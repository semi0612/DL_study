{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f5c8ec84-6d71-4892-b011-8fa61b412674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydataset\n",
    "mpg = pydataset.data('mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "21702629-4beb-4449-a209-d608ff479122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r    168\n",
       "p     52\n",
       "e      8\n",
       "d      5\n",
       "c      1\n",
       "Name: fl, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg['fl'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1d80f922-e5d5-4061-aadd-4e793e43927f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r    168\n",
       "p     52\n",
       "Name: fl, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg.drop(index = mpg[(mpg['fl'] == 'e')].index, inplace=True)\n",
    "mpg.drop(index = mpg[mpg['fl'] == 'd'].index, inplace=True)\n",
    "mpg.drop(index = mpg[mpg['fl'] == 'c'].index, inplace=True)\n",
    "mpg['fl'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b46d6d6d-31e0-4b31-97d4-0064fbd094ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = mpg.drop(['fl'], axis = 1)\n",
    "y_labels = mpg['fl'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9afe7dbf-3876-4791-b3f6-5b337ca3be57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 220 entries, 1 to 234\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   manufacturer  220 non-null    object \n",
      " 1   model         220 non-null    object \n",
      " 2   displ         220 non-null    float64\n",
      " 3   year          220 non-null    int64  \n",
      " 4   cyl           220 non-null    int64  \n",
      " 5   trans         220 non-null    object \n",
      " 6   drv           220 non-null    object \n",
      " 7   cty           220 non-null    int64  \n",
      " 8   hwy           220 non-null    int64  \n",
      " 9   class         220 non-null    object \n",
      "dtypes: float64(1), int64(4), object(5)\n",
      "memory usage: 18.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 피처값에 문자열이 존재한다 이를 레이블 인코딩 하시오\n",
    "X_features.info()\n",
    "\n",
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "# Int64Index: 220 entries, 1 to 234\n",
    "# Data columns (total 10 columns):\n",
    "#  #   Column        Non-Null Count  Dtype  \n",
    "# ---  ------        --------------  -----  \n",
    "#  0   manufacturer  220 non-null    object \n",
    "#  1   model         220 non-null    object \n",
    "#  2   displ         220 non-null    float64\n",
    "#  3   year          220 non-null    int64  \n",
    "#  4   cyl           220 non-null    int64  \n",
    "#  5   trans         220 non-null    object \n",
    "#  6   drv           220 non-null    object \n",
    "#  7   cty           220 non-null    int64  \n",
    "#  8   hwy           220 non-null    int64  \n",
    "#  9   class         220 non-null    object \n",
    "# dtypes: float64(1), int64(4), object(5)\n",
    "# memory usage: 18.9+ KB\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y_labels = encoder.fit_transform(y_labels)\n",
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d19f7696-db6a-43ef-9349-3f65efd3fac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>displ</th>\n",
       "      <th>year</th>\n",
       "      <th>cyl</th>\n",
       "      <th>trans</th>\n",
       "      <th>drv</th>\n",
       "      <th>cty</th>\n",
       "      <th>hwy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     manufacturer  model  displ  year  cyl  trans  drv  cty  hwy  class\n",
       "1               0      1    1.8  1999    4      3    1   18   29      1\n",
       "2               0      1    1.8  1999    4      8    1   21   29      1\n",
       "3               0      1    2.0  2008    4      9    1   20   31      1\n",
       "4               0      1    2.0  2008    4      0    1   21   30      1\n",
       "5               0      1    2.8  1999    6      3    1   16   26      1\n",
       "..            ...    ...    ...   ...  ...    ...  ...  ...  ...    ...\n",
       "230            14     31    2.0  2008    4      7    1   19   28      2\n",
       "231            14     31    2.0  2008    4      9    1   21   29      2\n",
       "232            14     31    2.8  1999    6      3    1   16   26      2\n",
       "233            14     31    2.8  1999    6      8    1   18   26      2\n",
       "234            14     31    3.6  2008    6      7    1   17   26      2\n",
       "\n",
       "[220 rows x 10 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = X_features.columns\n",
    "\n",
    "for column in ['manufacturer', 'model', 'trans', 'drv', 'class']:\n",
    "    X_features[column] = encoder.fit_transform(X_features[column])\n",
    "\n",
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dcd9d16c-2736-452c-b1e0-4398946c9b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7045454545454546\n"
     ]
    }
   ],
   "source": [
    "# 교차검증\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_val_score(dt_clf, X_features, y_labels, scoring = 'accuracy', cv = 5)\n",
    "print(f'정확도 : {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff57876-43bb-4aa0-a604-59702dd104f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08400118-8fda-4a28-aa38-df9429963cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7a5c0ef4-b47d-4f00-895f-b7d3446e324b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 읽어오기\n",
    "card_df = pd.read_csv(\"./creditcard.csv/creditcard.csv\")\n",
    "card_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b89dd791-6ca7-4fe2-8ed7-6b48abf042fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8051be4-8ba9-440c-b229-538db2978094",
   "metadata": {},
   "source": [
    "## 언더 샘플링과 오버 샘플링의 이해\n",
    "레이블이 불균형한 분포를 가진 Data set를 학습 시킬 때 예측성능의 문제가 발생할 수 있다. 이살 레이블을 가지는 데이터 건수가 매우 적기 때문에 제대로 다양한 유형을 학습하지 못하는 반면 정상 레이블을 가지는 데이터 건수가 매우 많기 때문에 생기는 문제이다. 그렇기 때문에 적절한 학습 데이터를 확보하는 방안이 필요한데, 대표적으로 언더 샘플링과 오버 샘플링이 있다.\n",
    "\n",
    "### 언더 샘플링\n",
    "- 많은 데이터 셋을 적은 데이터 셋 수준으로 감소시키는 방식\n",
    "- 정상 레이블이 10,000건, 이상레이블이 100 건이라면 정상 레이블 데이터도 100건으로 줄여버린다\n",
    "- 과도하게 정상 레이블로 학습/예측하는 부작용은 개선되었지만 과도한 데이터 감소로 오히려 정상 레이블의 제대로된 학습 수행이 어려울 수 있다.\n",
    "\n",
    "### 오버 샘플링\n",
    "- 예측 성능상 더 유리한 경우가 많아 주로 사용된다\n",
    "- 적은 데이터 셋을 많은 데이터 셋 수준으로 증가하여 맞추는 방식\n",
    "- 단순히 동일 데이터를 증식한다면 과적합 될 수 있기 때문에, 원본 데이터 피처값을 약간 변경하며 증식한다\n",
    "- 대표적으로는 SMOTE(Synthetic Minority Over-sampling Technique) 방법이 있다\n",
    "- SMOTE 는 적은 데이터 셋에 있는 개별 데이터들의 K최근접 이웃(KNN)을 찾아 데이터와 K개의 이웃들 차이를 일정 값으로 만들어 기존 데이터와 약간의 차이가 나는 새로운 데이터들을 생성하는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "719da387-413b-4c80-8cf9-fba28672e438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V21       V22  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time 컬럼은 크게 필요치 않아 제거한다.\n",
    "card_df.drop(['Time'], axis=1, inplace=True)\n",
    "card_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "401ffea4-4cda-4ccc-a48c-ea9239dcd89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_features = card_df.iloc[:,:-1]\n",
    "y_lables = card_df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_lables, test_size=0.3, random_state=0, stratify=y_lables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa9d143-c98f-46ca-bf2e-5dd0b95cddcb",
   "metadata": {},
   "source": [
    "stratify?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ddbc9f58-3054-46f1-bef8-6c099cc80ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 레이블 값 비율\n",
      "0    0.998275\n",
      "1    0.001725\n",
      "Name: Class, dtype: float64\n",
      "\n",
      "테스트 데이터 레이블 값 비율\n",
      "0    0.998268\n",
      "1    0.001732\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 나눠진 데이터 셋트들의 비율을 서로 환산하여 분할 비율 확인\n",
    "print('학습데이터 레이블 값 비율')\n",
    "print(y_train.value_counts()/len(y_train))\n",
    "print()\n",
    "print('테스트 데이터 레이블 값 비율')\n",
    "print(y_test.value_counts()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd654f9d-2f59-4175-86e2-593f7d18a4ec",
   "metadata": {},
   "source": [
    "학습 데이터와 테스트 데이터의 1값이 약 0.0017로 큰차이없이 분할된것을 확인해 볼 수 있다.\n",
    "\n",
    "먼저 로지스틱 회귀를 이용하여 사기 여부를 예측해보겠다. 성능 평가는 전에 정의했던 사용자 함수 `get_clf_eval()` 함수를 다시 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0ac2a395-ae9c-46a3-8f9c-d1f2ee48f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "# 학습/예측\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "\n",
    "# output이 두개가 나오는데 뒤( =1값 =positive값)만 취하겠다.\n",
    "lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2972ab15-41d6-4423-9f17-1bd9e2298648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의함수\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion, '\\n')\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a1adb4f4-30e1-4bd6-856d-6c930d4636b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85281    14]\n",
      " [   57    91]] \n",
      "\n",
      "정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "get_clf_eval(y_test, preds, lr_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8d350d-c846-46a2-b666-cd338a034144",
   "metadata": {},
   "source": [
    "이번에는 LGBMClassifier를 이용하여 모델을 학습한 뒤 별도의 테스트 데이터셋에서 예측 평가를 수행해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf470598-8d5a-4974-a51c-68d408746598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85290     5]\n",
      " [   36   112]] \n",
      "\n",
      "정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성, fit, predict, evaluate\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "preds = lgbm_clf.predict(X_test)\n",
    "lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 오차행렬, 정확도, 정밀도, 재현율, f1, auc\n",
    "get_clf_eval(y_test, preds, lgbm_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc758cb1-a0fe-4631-98a9-76d99fcd7382",
   "metadata": {},
   "source": [
    "## 추가적으로 데이터 정제 후 적용\n",
    "### 표준 정규분포 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ab4d77a9-3e6b-4952-bead-aa09ef820568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284807.000000\n",
       "mean         88.349619\n",
       "std         250.120109\n",
       "min           0.000000\n",
       "25%           5.600000\n",
       "50%          22.000000\n",
       "75%          77.165000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_df['Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1368f814-5ab8-45e2-96cc-ae74722268d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAGSCAYAAAAl7Z1YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABta0lEQVR4nO3deVxU9foH8M8MAqI44AqiKKi5oIiKiahpJIqGlel1Kfet8qKplKgtuNRNr97ccsurhv1KUyu7Ku57KYmilCvlkpgKWgrjxjrP7w+aIyOYM3COIHzerxcvnXO+POdhBmae+c73PEcnIgIiIiIiIrKavqgTICIiIiJ60rCIJiIiIiKyEYtoIiIiIiIbsYgmIiIiIrIRi2giIiIiIhuxiCYiIiIishGLaCIiIiIiG7GIJiIiIiKyUZmiTqA0MZlMuHLlCipUqACdTlfU6RARERHRA0QEt27dgoeHB/T6h883s4h+jK5cuQJPT8+iToOIiIiIHuHSpUuoWbPmQ/eziH6MKlSoACDnQTEYDEWcDRERERE9yGg0wtPTU6nbHoZF9GNkXsJhMBhYRBMREREVY49aessTC4mIiIiIbMQimoiIiIjIRiyiiYiIiIhsxCKaiIiIiMhGLKKJiIiIiGzEIpqIiIiIyEYsoomIiIiIbMQimoiIiIjIRiyiiYiIiIhsxCKaiIiIiMhGLKJLsAHLD+Efiw/i2q20ok6FiIiIqEQpU9QJkHaO/HYT9zKzkZ5pKupUiIiIiEoUzkSXYHpdzr8mkaJNhIiIiKiEKdIi2svLCzqdLs9XWFgYACAtLQ1hYWGoXLkynJ2d0bNnTyQnJ1vESExMRGhoKMqVK4dq1aph/PjxyMrKshizd+9etGjRAo6OjqhXrx6ioqLy5LJw4UJ4eXmhbNmyCAgIQGxsrMV+a3IpbvR/VdHZJhbRRERERGoq0iL68OHDuHr1qvK1Y8cOAECvXr0AAOPGjcPGjRuxbt067Nu3D1euXEGPHj2U78/OzkZoaCgyMjJw8OBBrFy5ElFRUYiMjFTGXLhwAaGhoQgKCkJ8fDzGjh2L4cOHY9u2bcqYNWvWIDw8HJMnT8bRo0fh5+eHkJAQXLt2TRnzqFyKI7u/imjORBMRERGpTIqRMWPGSN26dcVkMklKSorY29vLunXrlP2nT58WABITEyMiIps3bxa9Xi9JSUnKmMWLF4vBYJD09HQREYmIiJDGjRtbHKdPnz4SEhKi3G7VqpWEhYUpt7Ozs8XDw0OmT58uImJVLtZITU0VAJKammr19xRGi2nbpfaETXLmqvGxHI+IiIjoSWdtvVZs1kRnZGTgiy++wNChQ6HT6RAXF4fMzEwEBwcrYxo2bIhatWohJiYGABATEwNfX1+4ubkpY0JCQmA0GnHy5EllTO4Y5jHmGBkZGYiLi7MYo9frERwcrIyxJpfiiMs5iIiIiLRRbLpzfPfdd0hJScHgwYMBAElJSXBwcICrq6vFODc3NyQlJSljchfQ5v3mfX83xmg04t69e7h58yays7PzHXPmzBmrc8lPeno60tPTldtGo/Fv7gH12em4nIOIiIhIC8VmJnr58uXo2rUrPDw8ijoV1UyfPh0uLi7Kl6en52M9PrtzEBEREWmjWBTRFy9exM6dOzF8+HBlm7u7OzIyMpCSkmIxNjk5Ge7u7sqYBztkmG8/aozBYICTkxOqVKkCOzu7fMfkjvGoXPIzadIkpKamKl+XLl16xD2hLi7nICIiItJGsSiiP/vsM1SrVg2hoaHKNn9/f9jb22PXrl3KtoSEBCQmJiIwMBAAEBgYiOPHj1t00dixYwcMBgN8fHyUMbljmMeYYzg4OMDf399ijMlkwq5du5Qx1uSSH0dHRxgMBouvx4ndOYiIiIi0UeRrok0mEz777DMMGjQIZcrcT8fFxQXDhg1DeHg4KlWqBIPBgNGjRyMwMBCtW7cGAHTu3Bk+Pj4YMGAAZs6ciaSkJLz33nsICwuDo6MjAOCNN97AggULEBERgaFDh2L37t1Yu3YtoqOjlWOFh4dj0KBBaNmyJVq1aoW5c+fizp07GDJkiNW5FEfmNdHZvGAhERERkaqKvIjeuXMnEhMTMXTo0Dz75syZA71ej549eyI9PR0hISFYtGiRst/Ozg6bNm3CyJEjERgYiPLly2PQoEGYNm2aMsbb2xvR0dEYN24c5s2bh5o1a2LZsmUICQlRxvTp0wfXr19HZGQkkpKS0KxZM2zdutXiZMNH5VIccTkHERERkTZ0Ivys/3ExGo1wcXFBamrqY1naETJnPxKSb2HV8AC0qVdF8+MRERERPemsrdeKxZpo0sZfqzmQzfdJRERERKpiEV2C2XE5BxEREZEmWESXYOzOQURERKQNFtElmJ7dOYiIiIg0wSK6BONyDiIiIiJtsIguwcyX/WYDFiIiIiJ1sYguwZTlHCyiiYiIiFTFIroE43IOIiIiIm2wiC7B2J2DiIiISBssokswducgIiIi0gaL6BKMM9FERERE2mARXYKZu3OYuCaaiIiISFUsokswducgIiIi0gaL6BJMWc7BmWgiIiIiVbGILsH0bHFHREREpAkW0SWYnbKco4gTISIiIiphWESXYOblHLzsNxEREZG6WESXYH9NRHM5BxEREZHKWESXYHbszkFERESkCRbRJRi7cxARERFpg0V0CXa/O0cRJ0JERERUwrCILsG4nIOIiIhIGyyiSzDzZb/ZnYOIiIhIXSyiSzBebIWIiIhIGyyiSzAu5yAiIiLSBovoEozdOYiIiIi0wSK6BGN3DiIiIiJtsIguwczLOUxczkFERESkKhbRJZi5OweLaCIiIiJ1sYguwdidg4iIiEgbRV5EX758Gf3790flypXh5OQEX19fHDlyRNkvIoiMjET16tXh5OSE4OBg/PrrrxYxbty4gX79+sFgMMDV1RXDhg3D7du3Lcb8/PPPeOaZZ1C2bFl4enpi5syZeXJZt24dGjZsiLJly8LX1xebN2+22G9NLsUJl3MQERERaaNIi+ibN2+ibdu2sLe3x5YtW3Dq1Cl8/PHHqFixojJm5syZmD9/PpYsWYJDhw6hfPnyCAkJQVpamjKmX79+OHnyJHbs2IFNmzZh//79eO2115T9RqMRnTt3Ru3atREXF4dZs2ZhypQpWLp0qTLm4MGDeOWVVzBs2DAcO3YM3bt3R/fu3XHixAmbcilOOBNNREREpBEpQhMmTJB27do9dL/JZBJ3d3eZNWuWsi0lJUUcHR1l9erVIiJy6tQpASCHDx9WxmzZskV0Op1cvnxZREQWLVokFStWlPT0dItjN2jQQLndu3dvCQ0NtTh+QECAvP7661bn8iipqakCQFJTU60aX1iL956V2hM2Sfia+MdyPCIiIqInnbX1WpHORG/YsAEtW7ZEr169UK1aNTRv3hz//e9/lf0XLlxAUlISgoODlW0uLi4ICAhATEwMACAmJgaurq5o2bKlMiY4OBh6vR6HDh1SxrRv3x4ODg7KmJCQECQkJODmzZvKmNzHMY8xH8eaXIob83IO4XIOIiIiIlUVaRF9/vx5LF68GE899RS2bduGkSNH4s0338TKlSsBAElJSQAANzc3i+9zc3NT9iUlJaFatWoW+8uUKYNKlSpZjMkvRu5jPGxM7v2PyuVB6enpMBqNFl+P0181NK9YSERERKSyMkV5cJPJhJYtW+Kjjz4CADRv3hwnTpzAkiVLMGjQoKJMTRXTp0/H1KlTi+z4dlwTTURERKSJIp2Jrl69Onx8fCy2NWrUCImJiQAAd3d3AEBycrLFmOTkZGWfu7s7rl27ZrE/KysLN27csBiTX4zcx3jYmNz7H5XLgyZNmoTU1FTl69KlS/mO04py2W/ORBMRERGpqkiL6LZt2yIhIcFi2y+//ILatWsDALy9veHu7o5du3Yp+41GIw4dOoTAwEAAQGBgIFJSUhAXF6eM2b17N0wmEwICApQx+/fvR2ZmpjJmx44daNCggdIJJDAw0OI45jHm41iTy4McHR1hMBgsvh4nvY4z0URERERaKNIiety4cfjxxx/x0Ucf4ezZs1i1ahWWLl2KsLAwAIBOp8PYsWPx4YcfYsOGDTh+/DgGDhwIDw8PdO/eHUDOzHWXLl0wYsQIxMbG4sCBAxg1ahT69u0LDw8PAMCrr74KBwcHDBs2DCdPnsSaNWswb948hIeHK7mMGTMGW7duxccff4wzZ85gypQpOHLkCEaNGmV1LsXN/eUcRZwIERERUUnzeJqFPNzGjRulSZMm4ujoKA0bNpSlS5da7DeZTPL++++Lm5ubODo6SseOHSUhIcFizJ9//imvvPKKODs7i8FgkCFDhsitW7csxvz000/Srl07cXR0lBo1asiMGTPy5LJ27VqpX7++ODg4SOPGjSU6OtrmXP7O425x91XsRak9YZMM/Sz2sRyPiIiI6Elnbb2mE+GC2cfFaDTCxcUFqampj2Vpx7ojlzD+65/xbIOqiBrSSvPjERERET3prK3Xivyy36QdducgIiIi0gaL6BKM3TmIiIiItMEiugRjdw4iIiIibbCILsGUmWh25yAiIiJSFYvoEuyvGprLOYiIiIhUxiK6BFOWc7CIJiIiIlIVi+gS7P5yDhbRRERERGpiEV2C6fWciSYiIiLSAovoEsxOx8t+ExEREWmBRXQJZl7OwYtSEhEREamLRXQJ9tdENPtEExEREamMRXQJZsfuHERERESaYBFdgrE7BxEREZE2WESXYOzOQURERKQNFtElmHk5By/7TURERKQuFtElmPmKhbzsNxEREZG6WESXYPq/Hl125yAiIiJSF4voEkw5sZAz0URERESqYhFdgt2/YiGLaCIiIiI1sYguwZTuHCyiiYiIiFTFIroEU7pzsIYmIiIiUhWL6BKM3TmIiIiItMEiugRjdw4iIiIibbCILsHYnYOIiIhIGyyiSzB25yAiIiLSBovoEkyvv39ioXA2moiIiEg1LKJLMPNMNMAOHURERERqYhFdguktimhW0URERERqYRFdgulzPbpcF01ERESkHhbRJZi5OwfAmWgiIiIiNRVpET1lyhTodDqLr4YNGyr709LSEBYWhsqVK8PZ2Rk9e/ZEcnKyRYzExESEhoaiXLlyqFatGsaPH4+srCyLMXv37kWLFi3g6OiIevXqISoqKk8uCxcuhJeXF8qWLYuAgADExsZa7Lcml+Im93IOzkQTERERqafIZ6IbN26Mq1evKl8//PCDsm/cuHHYuHEj1q1bh3379uHKlSvo0aOHsj87OxuhoaHIyMjAwYMHsXLlSkRFRSEyMlIZc+HCBYSGhiIoKAjx8fEYO3Yshg8fjm3btilj1qxZg/DwcEyePBlHjx6Fn58fQkJCcO3aNatzKY4sZqJNRZgIERERUUkjRWjy5Mni5+eX776UlBSxt7eXdevWKdtOnz4tACQmJkZERDZv3ix6vV6SkpKUMYsXLxaDwSDp6ekiIhIRESGNGze2iN2nTx8JCQlRbrdq1UrCwsKU29nZ2eLh4SHTp0+3OhdrpKamCgBJTU21+nsKIzvbJLUnbJLaEzbJjdvpj+WYRERERE8ya+u1Ip+J/vXXX+Hh4YE6deqgX79+SExMBADExcUhMzMTwcHBytiGDRuiVq1aiImJAQDExMTA19cXbm5uypiQkBAYjUacPHlSGZM7hnmMOUZGRgbi4uIsxuj1egQHBytjrMmlOMq1mgPZXBNNREREpJoyRXnwgIAAREVFoUGDBrh69SqmTp2KZ555BidOnEBSUhIcHBzg6upq8T1ubm5ISkoCACQlJVkU0Ob95n1/N8ZoNOLevXu4efMmsrOz8x1z5swZJcajcslPeno60tPTldtGo/ER94i6dDod9LqcHtEmrokmIiIiUk2RFtFdu3ZV/t+0aVMEBASgdu3aWLt2LZycnIowM3VMnz4dU6dOLdIc7PQ6mLKFM9FEREREKiry5Ry5ubq6on79+jh79izc3d2RkZGBlJQUizHJyclwd3cHALi7u+fpkGG+/agxBoMBTk5OqFKlCuzs7PIdkzvGo3LJz6RJk5Camqp8Xbp0ybo7QkXmDh3szkFERESknmJVRN++fRvnzp1D9erV4e/vD3t7e+zatUvZn5CQgMTERAQGBgIAAgMDcfz4cYsuGjt27IDBYICPj48yJncM8xhzDAcHB/j7+1uMMZlM2LVrlzLGmlzy4+joCIPBYPH1uJk7dLA7BxEREZF6inQ5x9tvv40XXngBtWvXxpUrVzB58mTY2dnhlVdegYuLC4YNG4bw8HBUqlQJBoMBo0ePRmBgIFq3bg0A6Ny5M3x8fDBgwADMnDkTSUlJeO+99xAWFgZHR0cAwBtvvIEFCxYgIiICQ4cOxe7du7F27VpER0creYSHh2PQoEFo2bIlWrVqhblz5+LOnTsYMmQIAFiVS3FlnonmxVaIiIiI1FOkRfTvv/+OV155BX/++SeqVq2Kdu3a4ccff0TVqlUBAHPmzIFer0fPnj2Rnp6OkJAQLFq0SPl+Ozs7bNq0CSNHjkRgYCDKly+PQYMGYdq0acoYb29vREdHY9y4cZg3bx5q1qyJZcuWISQkRBnTp08fXL9+HZGRkUhKSkKzZs2wdetWi5MNH5VLcWVuFc010URERETq0YmwunpcjEYjXFxckJqa+tiWdjSfth0372Zix7j2eMqtwmM5JhEREdGTytp6rVitiSb1mddEcyaaiIiISD0soks4ducgIiIiUh+L6BKO3TmIiIiI1MciuoRjdw4iIiIi9bGILuH0fz3CXBNNREREpB4W0SWcnXkmmmuiiYiIiFTDIrqE0+t5YiERERGR2lhEl3DmmWgu5yAiIiJSD4voEs7cnYM1NBEREZF6WESXcDr2iSYiIiJSHYvoEs6O3TmIiIiIVMciuoRjdw4iIiIi9bGILuHYnYOIiIhIfSyiSzg7XrGQiIiISHUsoku4+5f9LuJEiIiIiEoQFtElnHLZb1bRRERERKphEV3CmftEczkHERERkXpYRJdwevaJJiIiIlIdi+gSzo7dOYiIiIhUxyK6hGN3DiIiIiL1sYgu4XTszkFERESkOhbRJZwdu3MQERERqY5FdAnH7hxERERE6mMRXcKxOwcRERGR+lhEl3DszkFERESkPhbRJRy7cxARERGpj0V0CcfuHERERETqK1ARXadOHfz55595tqekpKBOnTqFTorUw+4cREREROorUBH922+/ITs7O8/29PR0XL58udBJkXqU7hwsoomIiIhUU8aWwRs2bFD+v23bNri4uCi3s7OzsWvXLnh5eamWHBWe0p2Da6KJiIiIVGPTTHT37t3RvXt36HQ6DBo0SLndvXt39O3bFzt27MDHH39coERmzJgBnU6HsWPHKtvS0tIQFhaGypUrw9nZGT179kRycrLF9yUmJiI0NBTlypVDtWrVMH78eGRlZVmM2bt3L1q0aAFHR0fUq1cPUVFReY6/cOFCeHl5oWzZsggICEBsbKzFfmtyKY44E01ERESkPpuKaJPJBJPJhFq1auHatWvKbZPJhPT0dCQkJKBbt242J3H48GF8+umnaNq0qcX2cePGYePGjVi3bh327duHK1euoEePHsr+7OxshIaGIiMjAwcPHsTKlSsRFRWFyMhIZcyFCxcQGhqKoKAgxMfHY+zYsRg+fDi2bdumjFmzZg3Cw8MxefJkHD16FH5+fggJCcG1a9eszqW40vPEQiIiIiL1SRG7deuWPPXUU7Jjxw7p0KGDjBkzRkREUlJSxN7eXtatW6eMPX36tACQmJgYERHZvHmz6PV6SUpKUsYsXrxYDAaDpKeni4hIRESENG7c2OKYffr0kZCQEOV2q1atJCwsTLmdnZ0tHh4eMn36dKtzsUZqaqoAkNTUVKu/p7CmbjgptSdskhlbTj+2YxIRERE9qayt1wrc4m7Xrl145513MHz4cAwdOtTiyxZhYWEIDQ1FcHCwxfa4uDhkZmZabG/YsCFq1aqFmJgYAEBMTAx8fX3h5uamjAkJCYHRaMTJkyeVMQ/GDgkJUWJkZGQgLi7OYoxer0dwcLAyxppciitzdw4u5yAiIiJSj00nFppNnToV06ZNQ8uWLVG9enWlF7GtvvrqKxw9ehSHDx/Osy8pKQkODg5wdXW12O7m5oakpCRlTO4C2rzfvO/vxhiNRty7dw83b95EdnZ2vmPOnDljdS75SU9PR3p6unLbaDQ+dKxW9LxiIREREZHqClREL1myBFFRURgwYECBD3zp0iWMGTMGO3bsQNmyZQscpzibPn06pk6dWqQ52LE7BxEREZHqCrScIyMjA23atCnUgePi4nDt2jW0aNECZcqUQZkyZbBv3z7Mnz8fZcqUgZubGzIyMpCSkmLxfcnJyXB3dwcAuLu75+mQYb79qDEGgwFOTk6oUqUK7Ozs8h2TO8ajcsnPpEmTkJqaqnxdunTJujtHRezOQURERKS+AhXRw4cPx6pVqwp14I4dO+L48eOIj49Xvlq2bIl+/fop/7e3t8euXbuU70lISEBiYiICAwMBAIGBgTh+/LhFF40dO3bAYDDAx8dHGZM7hnmMOYaDgwP8/f0txphMJuzatUsZ4+/v/8hc8uPo6AiDwWDx9bjxst9ERERE6ivQco60tDQsXboUO3fuRNOmTWFvb2+xf/bs2Y+MUaFCBTRp0sRiW/ny5VG5cmVl+7BhwxAeHo5KlSrBYDBg9OjRCAwMROvWrQEAnTt3ho+PDwYMGICZM2ciKSkJ7733HsLCwuDo6AgAeOONN7BgwQJERERg6NCh2L17N9auXYvo6GjluOHh4Rg0aBBatmyJVq1aYe7cubhz5w6GDBkCAHBxcXlkLsUVl3MQERERqa9ARfTPP/+MZs2aAQBOnDhhsa+gJxnmZ86cOdDr9ejZsyfS09MREhKCRYsWKfvt7OywadMmjBw5EoGBgShfvjwGDRqEadOmKWO8vb0RHR2NcePGYd68eahZsyaWLVuGkJAQZUyfPn1w/fp1REZGIikpCc2aNcPWrVstTjZ8VC7FFbtzEBEREalPJ8IpysfFaDTCxcUFqampj21px6K9ZzFzawJ6+dfErF5+j+WYRERERE8qa+u1AveJpicDl3MQERERqa9AyzmCgoL+dtnG7t27C5wQqYvdOYiIiIjUV6Ai2rwe2iwzMxPx8fE4ceIEBg0apEZepBJ25yAiIiJSX4GK6Dlz5uS7fcqUKbh9+3ahEiJ12f31gQGXcxARERGpR9U10f3798eKFSvUDEmFxOUcREREROpTtYiOiYkpsZfwflLp/yqis1lEExEREammQMs5evToYXFbRHD16lUcOXIE77//viqJkTrslDXRLKKJiIiI1FKgItrFxcXitl6vR4MGDTBt2jR07txZlcRIHeaZaE5EExEREamnQEX0Z599pnYepBG9jss5iIiIiNRWoCLaLC4uDqdPnwYANG7cGM2bN1clKVKPctlvLucgIiIiUk2Biuhr166hb9++2Lt3L1xdXQEAKSkpCAoKwldffYWqVauqmSMVAmeiiYiIiNRXoO4co0ePxq1bt3Dy5EncuHEDN27cwIkTJ2A0GvHmm2+qnSMVgh27cxARERGprkAz0Vu3bsXOnTvRqFEjZZuPjw8WLlzIEwuLGXbnICIiIlJfgWaiTSYT7O3t82y3t7eHyWQqdFKkHl72m4iIiEh9BSqin3vuOYwZMwZXrlxRtl2+fBnjxo1Dx44dVUuOCo/LOYiIiIjUV6AiesGCBTAajfDy8kLdunVRt25deHt7w2g04pNPPlE7RyoEducgIiIiUl+B1kR7enri6NGj2LlzJ86cOQMAaNSoEYKDg1VNjgqP3TmIiIiI1GfTTPTu3bvh4+MDo9EInU6HTp06YfTo0Rg9ejSefvppNG7cGN9//71WuVIBcDkHERERkfpsKqLnzp2LESNGwGAw5Nnn4uKC119/HbNnz1YtOSo8ducgIiIiUp9NRfRPP/2ELl26PHR/586dERcXV+ikSD3szkFERESkPpuK6OTk5Hxb25mVKVMG169fL3RSpB7zcg4Tq2giIiIi1dhURNeoUQMnTpx46P6ff/4Z1atXL3RSpB5zd45sLucgIiIiUo1NRfTzzz+P999/H2lpaXn23bt3D5MnT0a3bt1US44Kj905iIiIiNRnU4u79957D99++y3q16+PUaNGoUGDBgCAM2fOYOHChcjOzsa7776rSaJUMFzOQURERKQ+m4poNzc3HDx4ECNHjsSkSZMgfy0R0Ol0CAkJwcKFC+Hm5qZJolQwykw0l3MQERERqcbmi63Url0bmzdvxs2bN3H27FmICJ566ilUrFhRi/yokPTszkFERESkugJdsRAAKlasiKefflrNXEgDXM5BREREpD6bTiykJw+7cxARERGpj0V0CcfuHERERETqYxFdwnE5BxEREZH6irSIXrx4MZo2bQqDwQCDwYDAwEBs2bJF2Z+WloawsDBUrlwZzs7O6NmzJ5KTky1iJCYmIjQ0FOXKlUO1atUwfvx4ZGVlWYzZu3cvWrRoAUdHR9SrVw9RUVF5clm4cCG8vLxQtmxZBAQEIDY21mK/NbkURzyxkIiIiEh9RVpE16xZEzNmzEBcXByOHDmC5557Di+99BJOnjwJABg3bhw2btyIdevWYd++fbhy5Qp69OihfH92djZCQ0ORkZGBgwcPYuXKlYiKikJkZKQy5sKFCwgNDUVQUBDi4+MxduxYDB8+HNu2bVPGrFmzBuHh4Zg8eTKOHj0KPz8/hISE4Nq1a8qYR+VSXOn1bHFHREREpDopZipWrCjLli2TlJQUsbe3l3Xr1in7Tp8+LQAkJiZGREQ2b94ser1ekpKSlDGLFy8Wg8Eg6enpIiISEREhjRs3tjhGnz59JCQkRLndqlUrCQsLU25nZ2eLh4eHTJ8+XUTEqlyskZqaKgAkNTXV6u8prKsp96T2hE1Sd1L0YzsmERER0ZPK2nqt2KyJzs7OxldffYU7d+4gMDAQcXFxyMzMRHBwsDKmYcOGqFWrFmJiYgAAMTEx8PX1tbjAS0hICIxGozKbHRMTYxHDPMYcIyMjA3FxcRZj9Ho9goODlTHW5FJc6dmdg4iIiEh1Be4TrZbjx48jMDAQaWlpcHZ2xvr16+Hj44P4+Hg4ODjA1dXVYrybmxuSkpIAAElJSXmukGi+/agxRqMR9+7dw82bN5GdnZ3vmDNnzigxHpVLftLT05Genq7cNhqNj7g31Gf315poEUBEoPvrNhEREREVXJHPRDdo0ADx8fE4dOgQRo4ciUGDBuHUqVNFnZYqpk+fDhcXF+XL09Pzsedg7s4BsM0dERERkVqKvIh2cHBAvXr14O/vj+nTp8PPzw/z5s2Du7s7MjIykJKSYjE+OTkZ7u7uAAB3d/c8HTLMtx81xmAwwMnJCVWqVIGdnV2+Y3LHeFQu+Zk0aRJSU1OVr0uXLll3p6go98wza2giIiIidRR5Ef0gk8mE9PR0+Pv7w97eHrt27VL2JSQkIDExEYGBgQCAwMBAHD9+3KKLxo4dO2AwGODj46OMyR3DPMYcw8HBAf7+/hZjTCYTdu3apYyxJpf8ODo6Ku37zF+PW+6ZaBPXRRMRERGpokjXRE+aNAldu3ZFrVq1cOvWLaxatQp79+7Ftm3b4OLigmHDhiE8PByVKlWCwWDA6NGjERgYiNatWwMAOnfuDB8fHwwYMAAzZ85EUlIS3nvvPYSFhcHR0REA8MYbb2DBggWIiIjA0KFDsXv3bqxduxbR0dFKHuHh4Rg0aBBatmyJVq1aYe7cubhz5w6GDBkCAFblUlzZ6bicg4iIiEhtRVpEX7t2DQMHDsTVq1fh4uKCpk2bYtu2bejUqRMAYM6cOdDr9ejZsyfS09MREhKCRYsWKd9vZ2eHTZs2YeTIkQgMDET58uUxaNAgTJs2TRnj7e2N6OhojBs3DvPmzUPNmjWxbNkyhISEKGP69OmD69evIzIyEklJSWjWrBm2bt1qcbLho3IprvS5Pmtghw4iIiIidehEWFk9LkajES4uLkhNTX1sSzuysk2o927OVSDjIzvBtZzDYzkuERER0ZPI2nqt2K2JJnWxOwcRERGR+lhEl3DszkFERESkPhbRpYB5NprdOYiIiIjUwSK6FDB36OByDiIiIiJ1sIguBcwdOlhEExEREamDRXQpYJ6J5nIOIiIiInWwiC4F9EoRXcSJEBEREZUQLKJLAb2ea6KJiIiI1MQiuhRgdw4iIiIidRXpZb9Je6PGjcetMq0Bu7J4671pKJd1CwBQ1bUCFsyZVcTZERERET2ZWESXcNdTbsGhVnlkpmejSdcBqFahLADgx1WzizgzIiIioicXl3OUAjrkLOfgag4iIiIidbCILgXMV/5mEU1ERESkDhbRpYC5xZ2AVTQRERGRGlhElwJ/TUSzTzQRERGRSlhElwL3l3OwiiYiIiJSA4voUkBZzsEamoiIiEgVLKJLAfNMNC+2QkRERKQOFtGlgE5ZFU1EREREamARXQrcn4ku2jyIiIiISgoW0aUATywkIiIiUheL6FLgfp9oIiIiIlIDi+hS4H6faJbRRERERGpgEV0K6NjijoiIiEhVLKJLgftroos2DyIiIqKSgkV0KaAU0VwVTURERKQKFtGlgB5czkFERESkJhbRpQCvWEhERESkLhbRpQBPLCQiIiJSF4voUsDc4o41NBEREZE6irSInj59Op5++mlUqFAB1apVQ/fu3ZGQkGAxJi0tDWFhYahcuTKcnZ3Rs2dPJCcnW4xJTExEaGgoypUrh2rVqmH8+PHIysqyGLN37160aNECjo6OqFevHqKiovLks3DhQnh5eaFs2bIICAhAbGyszbkUR7xiIREREZG6irSI3rdvH8LCwvDjjz9ix44dyMzMROfOnXHnzh1lzLhx47Bx40asW7cO+/btw5UrV9CjRw9lf3Z2NkJDQ5GRkYGDBw9i5cqViIqKQmRkpDLmwoULCA0NRVBQEOLj4zF27FgMHz4c27ZtU8asWbMG4eHhmDx5Mo4ePQo/Pz+EhITg2rVrVudSXOm5nIOIiIhIVTopRtOT169fR7Vq1bBv3z60b98eqampqFq1KlatWoV//OMfAIAzZ86gUaNGiImJQevWrbFlyxZ069YNV65cgZubGwBgyZIlmDBhAq5fvw4HBwdMmDAB0dHROHHihHKsvn37IiUlBVu3bgUABAQE4Omnn8aCBQsAACaTCZ6enhg9ejQmTpxoVS6PYjQa4eLigtTUVBgMBlXvu4fpM+QN3Gz6Cn5Jvo32T1VB81oVAQA/rpqNNZ8teSw5EBERET0prK3XitWa6NTUVABApUqVAABxcXHIzMxEcHCwMqZhw4aoVasWYmJiAAAxMTHw9fVVCmgACAkJgdFoxMmTJ5UxuWOYx5hjZGRkIC4uzmKMXq9HcHCwMsaaXIor5cTCIs6DiIiIqKQoU9QJmJlMJowdOxZt27ZFkyZNAABJSUlwcHCAq6urxVg3NzckJSUpY3IX0Ob95n1/N8ZoNOLevXu4efMmsrOz8x1z5swZq3N5UHp6OtLT05XbRqPxUXeDJszvlIrPZw5ERERET7ZiMxMdFhaGEydO4KuvvirqVFQzffp0uLi4KF+enp5FkwhPLCQiIiJSVbEookeNGoVNmzZhz549qFmzprLd3d0dGRkZSElJsRifnJwMd3d3ZcyDHTLMtx81xmAwwMnJCVWqVIGdnV2+Y3LHeFQuD5o0aRJSU1OVr0uXLllxb6jPfGKhqUiOTkRERFTyFGkRLSIYNWoU1q9fj927d8Pb29tiv7+/P+zt7bFr1y5lW0JCAhITExEYGAgACAwMxPHjxy26aOzYsQMGgwE+Pj7KmNwxzGPMMRwcHODv728xxmQyYdeuXcoYa3J5kKOjIwwGg8VXUVD6RHMmmoiIiEgVRbomOiwsDKtWrcL//vc/VKhQQVlb7OLiAicnJ7i4uGDYsGEIDw9HpUqVYDAYMHr0aAQGBirdMDp37gwfHx8MGDAAM2fORFJSEt577z2EhYXB0dERAPDGG29gwYIFiIiIwNChQ7F7926sXbsW0dHRSi7h4eEYNGgQWrZsiVatWmHu3Lm4c+cOhgwZouT0qFyKK16xkIiIiEhdRVpEL168GADw7LPPWmz/7LPPMHjwYADAnDlzoNfr0bNnT6SnpyMkJASLFi1SxtrZ2WHTpk0YOXIkAgMDUb58eQwaNAjTpk1Txnh7eyM6Ohrjxo3DvHnzULNmTSxbtgwhISHKmD59+uD69euIjIxEUlISmjVrhq1bt1qcbPioXIorvbImumjzICIiIiopilWf6JKuqPpEp7ccgPhLKWhZuyLa1qsCgH2iiYiIiPLzRPaJJm0oa6KLNAsiIiKikoNFdCmgY4s7IiIiIlWxiC4FeGIhERERkbpYRJcCPLGQiIiISF0soksBHcwXW2EVTURERKQGFtGlgI4z0URERESqYhFdCvDEQiIiIiJ1sYguBZQTC4s4DyIiIqKSgkV0KWB+kE2ciSYiIiJSBYvoUoAt7oiIiIjUxSK6FOCJhURERETqYhFdCty/7DeraCIiIiI1sIguBfRczkFERESkKhbRpYB5OQdPLCQiIiJSB4voUoAnFhIRERGpi0V0KaCcWFi0aRARERGVGCyiSwH9X6cWcjkHERERkTpYRJcCuvvtOYiIiIhIBSyiSwHlxEJW0URERESqYBFdCujAEwuJiIiI1MQiuhTQ84qFRERERKpiEV0KmFvc8cRCIiIiInWwiC4FdJyJJiIiIlIVi+hS4H5zDlbRRERERGpgEV0K8IqFREREROpiEV0K8MRCIiIiInWxiC4FlBMLuZyDiIiISBUsoksBZU00a2giIiIiVbCILgXud+dgFU1ERESkBhbRpQBPLCQiIiJSV5EW0fv378cLL7wADw8P6HQ6fPfddxb7RQSRkZGoXr06nJycEBwcjF9//dVizI0bN9CvXz8YDAa4urpi2LBhuH37tsWYn3/+Gc888wzKli0LT09PzJw5M08u69atQ8OGDVG2bFn4+vpi8+bNNudSXCknFhZtGkREREQlRpEW0Xfu3IGfnx8WLlyY7/6ZM2di/vz5WLJkCQ4dOoTy5csjJCQEaWlpyph+/frh5MmT2LFjBzZt2oT9+/fjtddeU/YbjUZ07twZtWvXRlxcHGbNmoUpU6Zg6dKlypiDBw/ilVdewbBhw3Ds2DF0794d3bt3x4kTJ2zKpbjSgVcsJCIiIlKVFBMAZP369cptk8kk7u7uMmvWLGVbSkqKODo6yurVq0VE5NSpUwJADh8+rIzZsmWL6HQ6uXz5soiILFq0SCpWrCjp6enKmAkTJkiDBg2U271795bQ0FCLfAICAuT111+3OhdrpKamCgBJTU21+nsKq/fg12XC1z9J7QmbpHHkVpm9PUFmb0+Q3oNff2w5EBERET0prK3Xiu2a6AsXLiApKQnBwcHKNhcXFwQEBCAmJgYAEBMTA1dXV7Rs2VIZExwcDL1ej0OHDilj2rdvDwcHB2VMSEgIEhIScPPmTWVM7uOYx5iPY00uxZleWRPNmWgiIiIiNZQp6gQeJikpCQDg5uZmsd3NzU3Zl5SUhGrVqlnsL1OmDCpVqmQxxtvbO08M876KFSsiKSnpkcd5VC75SU9PR3p6unLbaDT+zU+sPZbQREREROootjPRJcH06dPh4uKifHl6ehZJHrxiIREREZG6im0R7e7uDgBITk622J6cnKzsc3d3x7Vr1yz2Z2Vl4caNGxZj8ouR+xgPG5N7/6Nyyc+kSZOQmpqqfF26dOkRP7U2lCsWsoomIiIiUkWxLaK9vb3h7u6OXbt2KduMRiMOHTqEwMBAAEBgYCBSUlIQFxenjNm9ezdMJhMCAgKUMfv370dmZqYyZseOHWjQoAEqVqyojMl9HPMY83GsySU/jo6OMBgMFl9FQceZaCIiIiJVFWkRffv2bcTHxyM+Ph5Azgl88fHxSExMhE6nw9ixY/Hhhx9iw4YNOH78OAYOHAgPDw90794dANCoUSN06dIFI0aMQGxsLA4cOIBRo0ahb9++8PDwAAC8+uqrcHBwwLBhw3Dy5EmsWbMG8+bNQ3h4uJLHmDFjsHXrVnz88cc4c+YMpkyZgiNHjmDUqFEAYFUuxZlyYiFXRRMRERGpokhPLDxy5AiCgoKU2+bCdtCgQYiKikJERATu3LmD1157DSkpKWjXrh22bt2KsmXLKt/z5ZdfYtSoUejYsSP0ej169uyJ+fPnK/tdXFywfft2hIWFwd/fH1WqVEFkZKRFL+k2bdpg1apVeO+99/DOO+/gqaeewnfffYcmTZooY6zJpbhyKJPzXikzW5BlMqGMvth+AEFERET0RNAJ+549NkajES4uLkhNTX1sSzv6DHkDAa+Mw8K955BtEgxp4wWDkz1+XDUbaz5b8lhyICIiInpSWFuvcUqyFNDpdHB2zPnQ4VZ6VhFnQ0RERPTkYxFdSpiL6NtpLKKJiIiICotFdCnhXPavIpoz0URERESFxiK6lFBmollEExERERUai+hSogKXcxARERGphkV0KcHlHERERETqYRFdSnA5BxEREZF6WESXEuYi+k56FkwmtgYnIiIiKgwW0aVEOQc76HWAALiTwdloIiIiosJgEV1K6HQ6lOeSDiIiIiJVsIguRXjBFSIiIiJ1sIguRXhyIREREZE6WESXImxzR0RERKQOFtGlCGeiiYiIiNTBIroU4VULiYiIiNTBIroU4XIOIiIiInWwiC5Fci/n4OVWiIiIiAqORXQpUs6hDHQATAJk6R2KOh0iIiKiJxaL6FLETq9DOUc7AECG3qmIsyEiIiJ6crGILmXMSzrS7coWcSZERERETy4W0aWMuYjmTDQRERFRwbGILmUqONoDADI4E01ERERUYCyiS5nyZbkmmoiIiKiwWESXMvfXRJcr4kyIiIiInlwsoksZd0POMo7bDpVwJslYxNkQERERPZlYRJcyruUcUK+aMwBg4Z5zRZwNERER0ZOJRXQp1MqrEgBg089XcO767SLOhoiIiOjJwyK6FKpawRGu6UkQARZxNpqIiIjIZiyiS6kat38FAHwXfxmXbtwt4myIiIiInixlijoBKhq/xu6Gy3MNkOpYDZ0/2oA6qfHwds7Ggjmzijo1IiIiomKPM9GlVIYJCH2mJZzs7XCvTAWcqvwMjmR54nZ6VlGnRkRERFTssYi20cKFC+Hl5YWyZcsiICAAsbGxRZ1SgVWt4IgBrWujgXsFCICk8nXR7t+7sXDPWRbTRERERH+DyzlssGbNGoSHh2PJkiUICAjA3LlzERISgoSEBFSrVq2o0ysQJwc7dGnsjvpuztgR9ytS7jpj1rYELNxzFj7VDWhYvQLqVXWGh6sTPFydUNnZAeUcyqC8gx3K2PE9GBEREZVOLKJtMHv2bIwYMQJDhgwBACxZsgTR0dFYsWIFJk6cWMTZFU6dKs7I3jEbddt0w+Xy9XEXzjhy8SaOXLz50O9xLKNHeccyKO9oh/IOZVDesQzKOdihjF6HMnZ6y39z/d9OrwMA6HSADrq//v3rtk731/8f2J5rHJQxOdv1uvvf+9C4Od/52Oge7+GKhO4x/5CP+y4tisewFPzaEBEVSDVDWTzvW72o07DAItpKGRkZiIuLw6RJk5Rter0ewcHBiImJyfd70tPTkZ6ertxOTU0FABiNj+9KgZkZGUi7k7cXtCk7O8/29MwsBIeEwiSCm3cz8OeddPx5OxM/HfkRTpXckakviyy9A0SXMwN9Lx24dwf447H8JERERFRatajlina1yz+WY5nrNBH523E6edQIAgBcuXIFNWrUwMGDBxEYGKhsj4iIwL59+3Do0KE83zNlyhRMnTr1caZJRERERCq4dOkSatas+dD9nInW0KRJkxAeHq7cNplMuHHjBipXrvxYPgo3Go3w9PTEpUuXYDAYGJdxGVejuE9SrozLuIzLuCUlrla5ighu3boFDw+Pvx3HItpKVapUgZ2dHZKTky22Jycnw93dPd/vcXR0hKOjo8U2V1dXrVJ8KIPBoOovF+MyLuM+vpiMy7iMy7iM+/hjuri4PHIM2ytYycHBAf7+/ti1a5eyzWQyYdeuXRbLO4iIiIio5ONMtA3Cw8MxaNAgtGzZEq1atcLcuXNx584dpVsHEREREZUOLKJt0KdPH1y/fh2RkZFISkpCs2bNsHXrVri5uRV1avlydHTE5MmT8ywpYVzGZVx14z5JuTIu4zIu45aUuFrlai125yAiIiIishHXRBMRERER2YhFNBERERGRjVhEExERERHZiEU0EREREZGNWEQTEREREdmIRXQJk5WVBQDIzs4u4kzU9SQ1kXnScmW+T979YPYk5kxP3uOmVb5P2v1A9CC2uCtBvvrqK3z33Xc4deoUmjVrhu7du+Oll16CnZ2dJscTEeh0OuW2yWSCXq/u+7LMzEzY29trEt9kMkGn01n8DIWhZa7mmGrmazQaNbmkK6DNz69VvlreD/lR677JHUeL+5txtYn7pD1uWuWrZty7d+/izJkzuH37NgCgUaNGqFq1aqFzvHnzJo4cOYKbN28iMzMTHTp0QM2aNQsdV6t8GTeHVo9bflhElxB79uxBjx490LdvX1SsWBEJCQm4evUqRARz585FQECAZsdOTk5GhQoVUK5cOdVirl69Gt999x3Kly+PihUrIiIiQrmoTWGfcDMyMiAiSnP27OzsQr3R0DJXLfKdN28eNm/ejIyMDFSvXh0TJkyAn58fgLxvjAqbqxo/v1b5ank/mB06dAjR0dGoVKkSDAYDBgwYUOg3Wps2bUJ0dDQcHR1RtWpVhIeHw8nJqVAxtcqVce970h43rfLVIm5oaCh++eUXXLhwQSnEXnjhBYwePRplyhT8mnLPPvssrl69iuvXr6N27dowGo3o2bMn/vWvfyn3cUFolS/j5tDqccuXUInQrl07mThxonL71q1bEh0dLSNGjJCnn35a5syZIyaTSdVjrlmzRrp16ya+vr5Sr149GTt2rPz222/K/oIeb8yYMeLr6yvBwcEyePBgadasmdjb28v48eMLle/mzZtlwIAB0r59e3nuuedk+vTpFvuzsrKKTa5a5Ttq1Chp1qyZ9O/fX6ZMmSJt2rQRvV4v/fv3l+vXr6uSa8eOHfPkWtDfBa3y1SpublOnThUfHx/x9vaWp59+Wnx9faV+/fqyfPnyAsd87733xMfHR/z9/aVnz57y1FNPibOzs8yYMaPY5cq49z1pj5tW+WoRNyIiQpo0aSIHDx6UW7duycqVK+W1116Tpk2byosvvig//vhjgeJOmjRJmjZtKgkJCXLv3j3ZtWuXTJs2TerXry++vr4SHR1drPJl3BxaPW4PwyK6BLh165aEhobKlClT8uz7/fffZeLEiVK5cmXZvn27asc8d+6cODs7y4QJE2TWrFny73//W5566ikxGAx5Cihb/P7771KuXDnZu3eviIhkZ2fL+fPnZf78+eLh4SGNGjWSmJiYAuXr4uIiw4cPlzfffFNGjRolHh4eUrVqVfn888+LVa5a5Xv16lUxGAzy/fffK9vS0tJkw4YN0rBhQ6lataps3bq1WOSqZb5axc3t2rVrUq5cOVm/fr2IiKSkpMi2bdvkn//8p3h4eEivXr3kwoULNsW8fv26lC9fXjZv3qzkfPr0aZk2bZq4urrK008/LcePHy8WuTLufU/a46ZVvlrEvXfvnrRr105WrFiR51hRUVHSsWNHefnll+Xu3bs2xc3IyJCuXbvKxx9/bLH9zp07smfPHunbt6906NDBYtKoKPNl3BxaPW5/h0V0CWF+93XixIl8Z/1CQkJkxIgRqh1vyJAh0r17d4ttt27dko8//licnZ0lKChIkpKSbI576NAh8fPzk/Pnz1tsz8rKktjYWHnhhRekb9++cu/ePZvi9u3bV/7xj39Y5Hrq1CkZM2aMlC9fXgYMGCA3b94sFrlqle/p06elSZMmcuTIERGxnB2+evWqDBkyRNq2bSuXL18u8ly1zFeruLlt2bJF/P39JSUlxWL7tWvX5PPPP5eAgAB59913bYoZExMjTZs2zfMCkJGRIfv375fg4GAZOHCgpKenF3mujHvfk/a4aZWvFnGzsrLkpZdekq5du0p2dnae/T/++KOUL19e3nvvPZtyFREZPHiwtGjRQjIyMvLsO3PmjNSqVUtee+01m2JqlS/j3qfF4/Z3WESXEMePH5fGjRtL+/bt5dChQ3l+MT/44AN59tlnJTMzU5XjvfPOO9KrVy/ldu7j7d+/X/z9/Qv0Ed3vv/8urq6u8vbbb+e7f/PmzWJnZyc7d+60OmZ2draMHDlSwsLC8uwzGo2ycuVK8fPzk9WrVxd5rlrme/PmTalVq5b0798/z/FERA4fPiwGg0HWrVtX5Llqla+WcXM7efKkODg4yMKFC/Pdv2TJEtHpdHL06FGrY166dEkqVKggkZGR+e5fv3692NnZyZ49e4o8V8a970l73LTKV6u4X3/9tfj6+soXX3whaWlpefZHRETIgAEDbF7+dujQIWnWrJl88MEHcunSpTz7586dKy+++KLNs6Va5cu4ObR63B6GRXQJcv78eWnTpo04OTnJmDFjJCYmRs6ePSsnT56UBg0ayLRp01Q7VlRUlOh0uocWGm+++aa0bNlSjEajzbFXrFghvr6+8tFHH8mvv/6aZ39QUJAsXbrUppizZs0SJycnZenFg/7xj3/Is88+m+8f8+POVct8t23bJg0bNpQRI0bku9Ska9euNr/50SpXrfLVMm5uEydOlLZt28r69evl1q1bFvvu3LkjrVu3lm+//dammAsWLBBfX1+ZPXu2JCYm5tkfFBQky5YtKxa5Mu59T9rjplW+WsS9deuWDBo0SOzs7GTUqFFy7tw5i+ea119/XTp37mxzrvfu3ZN3331XKleuLD179pQ9e/ZIcnKysj8sLEzat29vc1yt8mXcHFo9bg/DIroEWr58uXh6eoqHh4fUqVNHatWqJS+++KLqxxk9erT4+/vLv/71Lzl37pzFvt27d0vDhg2tOknrweUn169fl7ffflu8vb2lZ8+esnLlSuUjwO3bt4ujo6OcPHnSplzv3LkjvXr1kuDgYPnyyy/l2rVrFvvXr18vLVq0yPPRaFHkqmW+t2/flkWLFklAQIB07NhRpk6dKsePH5fs7Gz55ptvxMHBweZ1iWrlqmW+j+N+MB/D/O+ZM2ckJCREKlasKG+99ZbExsYqhc6xY8fEyclJjh07ZlPev//+u4wcOVLq1q0rAwcOlHXr1il/YzExMVK2bFllmcrjzpVx88Y1e1IeN63yVTuuWe6i64svvpAaNWpI5cqVZdy4cTJlyhQZM2aMuLi42HxuSu7nqj179kijRo2kcuXK8uqrr8rQoUOlX79+UqlSJZvjapUv4+bQ6nH7O2xxV4Jt2rQJIgJ3d3fUr18fLi4uqsa/cOECZs+eje+//x7e3t5o06YN+vfvj7Nnz2LChAmoV68ePv/8c6ti3blzB6dOnYK7uzs8PT0BADt37sS//vUv3LhxA9nZ2fjzzz9RrVo1PPfcc5gzZ47N+R45cgSTJ09GQkICOnfujPbt2yMkJATJyckYMWIE6tati6ioqGKRq1r5ighu3LiBmJgY1K5dG02aNIFOp0N8fDwWLFiAM2fOICEhARkZGfD29kbXrl0xffr0IslVy3wf1/0A5LR8dHZ2Rvny5QEAixYtQmRkJKpWrYpGjRrh6tWryMjIQKNGjfDFF188Ml52djYSEhJQo0YN5W/466+/xsyZM5GZmQm9Xo/bt2+jbNmyaNmyJZYvX15kuTLufU/a46ZVvlrEzd1WtEKFCpg4cSKqV68Ok8mE//znP1i3bh2cnJxQsWJF9O3bF6+88opVueZue1m1alVMnDgRLVq0AABERUVh8+bNyMzMhKurK3r37o2uXbtaFVerfBk3h1aPmzVYRJPVLl26hFOnTuHXX39F586d4e3tDXt7e/zvf//DqlWr8OuvvyI+Pl4pUtauXav0//w7c+bMwZdffonk5GRcv34d7dq1w9ixY9GtWzcAwIYNG5CSkoLr16+jY8eOaNq0qVW9RP/44w8kJibi/Pnz6NSpk/IEvnjxYnz22WfIzMzE+fPnUalSJdSuXRtbtmx5ZL5a5apVvh9++CHWrFmDP//8E0lJSfDz88OwYcPwyiuvoHLlyjh8+DBu376NS5cuoUOHDvD09Cyy+1bLfLWKm9vatWvxf//3f7h48SLu3r2Lrl27IiIiAp6ensjMzMTs2bNx/fp1pKSkIDQ0FF27dkXZsmX/NuaKFSuwcuVKJCYm4o8//kCXLl0wevRotG/fHtnZ2Vi9ejVu3ryJK1euIDQ0FK1atYKDg0OR5Mq49z1pj5tW+WoRd+zYsdi9ezfc3NxQo0YN/PTTTzh58iTefPNN/Oc//wGQU7jfvn3bpomj0aNH44cffkCTJk1Qt25d7NixAzExMejduzcWLlyIypUrF+iCV1rly7g5tHrcrKbanDaVaKdPn5bmzZtLjRo1xMvLS3Q6nXTu3FnWrVsn2dnZkpaWJseOHZPjx4/LTz/9ZPUZ1sePH5eyZcvKkiVLZMuWLbJ9+3bp0qWL6HQ66d27d56lAdZKSEiQDh06SOXKlcXT01Ps7e3l1VdfVT4qNBqNsnHjRtm1a5fs27dPUlNTiyxXrfI9ceKEODg4yKpVqyQ+Pl5++eUXGThwoFSpUkU6deokhw8fLja5apmvVnFze1jLR2dnZ5k6daoyzpYTe8+dOydOTk7y0UcfyVdffSVfffWVBAQEiJ2dnYwYMSLPGtiizJVxLeM+aY+bVvmqHffv2opWr15dGjRooLSufHDpy995VNvLypUrK/2Fbel5r1W+jJtDq8fNFiyiySqBgYHy+uuvy6lTpyQrK0sOHjwozz33nFStWlXeeOMNm9sdmY0cOVJeeumlPNt37twpdevWlVq1asnPP/8sIrb9EQQEBMjQoUPlwIED8ttvv8m6deukUaNGUq5cOfnwww+LVa5a5Ttx4kR5/vnn82w/fPiwPP300+Li4iL79++3OV8tctUyX63i5vaolo8dOnSQK1eu2HSMUaNGSWhoaJ7ta9euFXd3d/Hx8clzLkJR5cq49z1pj5tW+WoR19q2orZ2XtCq7aVW+TJujsfRrvRRWETTI507d07q1auX552iSM5JAc7OztKpU6cCdeKYO3eutG3bVrmdnp6utBq7fv26dOzYUYYOHWpTzFOnTknNmjXzbe308ccfi6Ojo/Tv31/u3r1r04uNFrlqme/KlSulYcOGSo/me/fuWbQi7NWrl3Tq1CnfPp2PO1et8tUybm5atHz8z3/+Ix06dFBu536jeunSJWnbtq288cYbxSJXxr3vSXvctMpXi7hatRXVqu2lVvkybo7H0a70UVhE0yNlZ2dLmzZtLGYZc59de+rUKalRo4Z88803NsfesWOH6HQ6+eCDDyy2mxulz549Wxo3bqzMsFjj9u3b0rRpU/niiy+UbbmfwKOjo6VWrVryww8/FHmuWuZ7+PBhcXV1lX/+858W283v9levXi0NGjSwaTZIq1y1ylfLuLlp0fJx06ZNotPpZMGCBRbbzb9vM2bMkMaNG9u8jEir9pSMm+NJe9y0yleruFq1FdWq7aVW+TJujsfRrvTvsIimv2WeTYyIiBAnJyf58ssvlX2ZmZmSlZUlaWlp0qVLl4e+y3yUBQsWSMOGDeWVV16xWNskIvLDDz9IzZo15Y8//rA6X5PJJP3795fKlSsrl5gVEaVpe0pKirRq1Uo++uijIs31ceS7adMmqVWrlgQEBMiGDRss9h06dEiqVq1q0UOzKHNVO9/HETc3tVo+5jZ9+nSpW7euDB8+XOLj4y32xcbGSq1ateTq1avFIlfGve9Je9y0yleNuFq1FX1c7TS1ypdxc2jRrtQWLKLJam+//ba4ublJnz595MSJExb7WrduLZMnTy5Q3Lt378rSpUslKChI/P39ZcCAAbJ3715ZunSpNG3atEAfJaakpEj//v3Fz89PIiIi5OzZsxb7AwICZPr06cUiV63yNT/Z7Ny5U3r27Cmenp7SoUMH+fLLL+X9998XX1/fYnXfapWvVnEfdP78eRk1apT4+flJ9+7dZebMmXLlyhXZv3+/BAYGyoABA2yOaTQaZc6cOdKuXTsJCAiQUaNGyYkTJ2Tt2rUSEBCQ52PMosyVce970h43rfJVK+7t27clNjbW4gItO3bskGeffVaaNm0qjRs3Fnd3d2natKmMHTvWqpgmk0n++OMP2bhxo/z888/K88SxY8dk2LBh0rZtW6lSpYoYDAbx8/OTiRMnWv1za5Ev4+bQ8nErCLa4o79lMpmg1+thMpmQkZGBzz//HF9++SXOnDmDNm3aoGnTpoiNjcWJEydw8eJFq9qCHTt2DD/88ANOnjyJoKAg+Pr6wsfHB6dPn8bXX3+Nffv24fvvv0eDBg3Qrl07LFiwwOZ2YwBw8eJFLF68GHv37oXJZMLTTz8Nf39/bN++HXv37sWVK1ceGfdx5apWvt9//z22bduGkydPonXr1mjatCk6deoEo9GILVu2YP369fj+++9Rv359tG/fHh9++GGB2v6okauW+T6O+0GLlo+//PILDh06hISEBLRv3x7169eHl5cXjhw5gnXr1mHfvn2IjY3FU089pfTUtaaFmVbtKRk3x5P2uGmVrxZxtWorqlXbS63yZdwcj6NdqU00LdHpifXbb7/JrFmzpGnTphIaGioffvihHDx4UERyZkOWLVsmXbt2FX9/f3nnnXeUfY9y+PBhqV27tjRr1kzatm0rrq6uEhAQIO+//75y5q7RaBSj0WjTx+u///67ktPgwYNl9erVcuHCBRER2bdvn7z//vvSqlUr8fDwkH/+85+ye/fuIstVq3xjY2OlWrVqEhwcLC+++KL4+PhIq1atpH///hZrlNPS0uT27dtFmquW+WoVNzctWj6ePHlSnnrqKWnYsKE0btxYDAaDdOjQQWbMmCFXr14Vk8kk169fl99//11+++03q0/c1Ko9JePmeNIeN63y1SKuVm1FtWp7qVW+jJvjcbQrtRWLaMpX69atpU2bNjJ+/Hjp1auXtG7dWgICAmT8+PHKOiaRnE4Htnj66afl7bffVjol/PbbbzJmzBhp3LixdOvWTX766SdlrC3dHZ555hlp3ry59O/fX9q1aye1atWSTp06yZIlS+TWrVvK2bq29CbVKlet8m3Tpo2Eh4crL6aXL1+Wjz/+WDp27CjPPvusxYmftnSi0CJXLfPVKm5uWrR8bNeunbzxxhvKiak//fSTDBkyRHx8fKR3795y5swZZawtv29atadk3BxP2uOmVb5axNWqrahWbS+1ypdxczyOdqW2YhFNeWzYsEGqV68uN27cULbFx8fL+PHjJSAgQPr16ycXL160Oe6lS5ekadOmsn79ehG5fzKaiMj3338vfn5+Ur9+ffn9999tivvNN99I9erV5c8//1S2/fDDD9KrVy+pX7++jB8/3uYLEGiVq1b5Xrt2Tdq0aSMrVqwQEcsnkGPHjskLL7wgHh4eFi9kRZWrlvlqFTc3LVo+Xrp0SXx9fWXTpk15Ym7atEmeeuopadGihcXjUFS5Mu59T9rjplW+WsXVqq2oVm0vtcqXcXM8jnaltmIRTXmsWLFCmjVrpnSZyP2E+M0334i7u7v07t07zz5rvPDCCzJ48GDldu5WeWlpaVK3bl2ZN2+eTTFnzZolbdq0UT6az53Tp59+Ko6OjjJ69GgRsW3mUYtctcx34MCB0rlzZ+UKgQ8Wt35+fvLuu+8Wi1y1ylfLuGZatXzs0qWLjBgxIt+YKSkpUqtWLfnkk0+KRa6Me9+T9Lhpla9WcbVqK6pV20ut8mXcHI+jXamtWERTHqdOnRJPT8887ezMtm/fLp6enjbNwpqLr6VLl4per5f3339f2Zedna3M9A4aNEgGDx5sU0F24MABqV69urIu27xe0GzFihVSv359qy8/bbZkyRLVczXn6+HhoXq+mzZtEldXVxk2bJgyQ5W76B03bpy8/PLLNs0cf//996rft+b7b8OGDarma/7e6OhocXFxkcGDB6t2Pzx4DDVbPppjzp8/X+zt7WXOnDl5YoqI9O/fX4YPH27175tW7Sm1imv+udSOa77/tLof5s2bp+rjZo6t1f07d+5cTX7PtLgfRNRvK2oWHR0tXl5eqre9XLhwoTRq1Ej1fBk3h1aPW0GxiCYL2dnZcvfuXRk+fLgYDAZZsmRJnjEXL14ULy8vm68uZLZixQqpXLmyNGrUSLZu3SoiOS909+7dk2bNmsmUKVNsinfz5k3p1q2bVKxYUTZu3KhsNz95nzhxQurUqWPVyY/37t2zeHOwfPlyqVSpkvj4+MiWLVsKnauIyI0bN6RLly5SqVIl5ePPguZrMpksXpR27Nghnp6eUqNGDVm+fLncuHFDjEaj3LhxQ5o1aybvvfeeVTnevn1bLly4ILdu3ZLOnTurkmt+tm7dqkq+uXMSyTm50MfHR9zc3OS///1voeI+jBYtH+fNmyfOzs4SEBAghw4dyhOzoO2aIiIipHr16qq3pxw/frwmcbXKV6u4aj1umZmZkpKSonm+c+bM0eT3bPbs2VKuXDlV46rdVtRc9GdlZcmmTZukd+/eUrt2bdXaXl6/fl3mz58vwcHB0rJlS9XaoN64cUM++eSTQsc1mUzKjLBIzuvnggULCh03LS1NkpKSlNspKSmqxL13756cOnVKuZ2ZmSkbN26UXr16adau1BYsoumhpk2bJo6OjhIQECBbt26V5ORkOX/+vMybN0+qVKliU6zcJ51lZmbKnj17pHfv3uLg4CA+Pj7SvXt3adasmTRp0sTqmOnp6XLhwgW5d++epKeny2uvvSYODg7StWtXpWn7tWvXZPHixVKtWjWrYg4aNEief/55+eKLL5QXswMHDsjLL78szs7O0qBBgwLlKiKyePFiZS2XyWSSESNGiL29vXTp0qXA+c6bN0+2b99u8cJ78eJFCQsLEycnJ/H29pY2bdpI/fr1pVWrVlbnGhYWJkOGDFFuDx8+XBwcHOT5559XntBszVUk5+TM7du3y5o1a5RZiAsXLsjo0aMLle/q1auld+/e0qRJE+nevbvMmDFDfvzxR/noo4+kYsWKUqtWrQLFfZD5DUt2drbcu3dPPv30U2nfvr1Uq1ZNunfvLpGRkdKlSxepWbOmTTNu5jcAGRkZsmXLFunSpYvY2dlJ27ZtZfDgwdKmTRupW7dugdf6Xb58WRYuXCjPPfdcoXPN3dHkypUrsmjRokLHTUxMtPhkQK24W7dutViPmZSUJAsXLpSgoKBCxV27dq2cOnVKObE6LS1Ntm7dKp06dSrU4zZlyhSLmdyrV6+qcj+kpqbKmTNnJD4+XtLT0yUrK0u2bNkiISEhhf49M//umh+/7du3S3BwcIHjHj16VObPny+vv/66fPXVV8pz46lTp2TatGnSsWNHcXBwEF9fXxk5cqTNfxMPjv/1119l5cqV0rt3b6lWrZq0a9dO3nnnHauXKp49e1a++OILmTp1qsUM6I8//ihTpkyRTp06FSjfAwcOyMSJE6V3794WXScOHDggU6dOLfD98O9//1sWL14sly9ftvgZDxw4IB988IE899xzBYo7dOhQmTVrVp7tMTExMnXqVAkODi5Q3MGDB8vzzz+fZ4nG5cuX5YsvvpCePXsW6HFTC4toEpGcd7m530WaxcTEyMsvvyx6vV58fX2lcuXK4ufnZ/W16H/55ReZPHmy0tHhwIEDyr4//vhDDh8+LOPHj5chQ4bIsmXLJCEhwaq4P/30kwwePFgcHBykWbNmsmvXLrl165Z89dVXEhQUJDqdTpo3by5169aV+vXry+rVq626D+rUqSNNmzaV9u3by+jRo5V2bTExMRITEyMRERE25yqSM0Nsb28v169fV/7IMzMz5auvvpLOnTuLTqeTFi1a2JTv7t27xWAwyLZt25QnpNxn7F+7dk1mzJghU6dOla+//trqk0F37twpOp1OdDqdsnb4xo0bsnr1amnXrp3odDpp2bKlTbmK5LyotG3bVgwGg7Rs2TLPermC5rt7926pXLmyTJs2TWbOnCldu3YVnU4ndevWlf/85z9y9epV+eSTT2yOm5sWLR//rrvC1atXZdeuXTJ48GDp0aOHzJo1S44dO2ZVrlevXpUVK1ZIUFCQvPnmm8ob2OzsbDl27JgsX75cQkNDbW5Pef78eYmMjBQPDw954YUXlAso5I7bpUsXm+PGx8dLq1atZNGiRRaXA87Ozpbjx4/LsmXL5Pnnn7c57sGDB8Xd3T1POy1z3OXLlxeoTeehQ4ekYsWK8vXXX+dZEpSeni47d+6UAQMG2Py4HTp0SHQ6nej1evn888+V7SaTSY4ePVrgx+3kyZPSs2dPKVu2rAQGBsrXX3+t7Ltx40aB8/3tt9/k448/Fh8fH3n++eclIiJC9u7dKyI5s4c7d+6UQYMG2RRXq7aiP//8s7z//vsW3aTyW86VlpZm08ma8fHxEhAQIN7e3tKoUSMpV66cxf1rMpkkJSVFjEZjvq+vDxMXFyf16tWT4OBgad++vTg4OOS5qNXdu3clNTXVpvvh/PnzotPpxM7OToKDg2Xr1q3K34d5drog9+/BgwdFp9MprU9FciZzchfKqampNsc9dOiQlC9fXo4eParEWLt2rezcuVPi4uKUcWlpaTZ3h1ILi2gSkZzr1vfo0UMOHDggd+7cybP/t99+k8WLF8uGDRts6mzQpk0bCQkJkQ8//FC6desmFSpUkH379uUZZ+tsQrNmzWTAgAESHR0tL774orRt21bS0tLk6tWrsm/fPjl+/Lh88MEH8t///tfij+3vmEwmeeedd2TAgAEye/ZsadmypXTo0EGmT58uOp1OFi1aJCL5P/k+Sp06deSdd94RkZwngtjYWFm5cqX873//k++//17i4+Pl/fffl2XLllmdb7NmzZQiNyEhQaZMmSLPP/+8vPDCC/LFF19Y/Fy28Pb2ln/9618SFRUlXl5eyjKOzMxMSU5OltjYWHn33XdtylVExMfHRyIiIuTUqVMyffp0ad68uZw9e1a2b99usVTE1nzbtGljUZAnJiZKy5YtpUePHuLn5ycLFy4UkYK3sxPRpuVjr169JDIy8pGXac69Bt0aoaGh0qpVK+nTp4/Ur19fvL29LT4OLUiuIiLt27eXkJAQmTVrlvj4+Ei3bt2UF17ziT0FiRsZGSk6nU4aN24sPXr0kHXr1ikv7LkvFW1r3EaNGsmbb74pIjm/u4mJibJ7925JTEy0uE9tjduyZUsZN26ciOR8dL9y5Up56623JDIyUn788UdlnK0t6Hx8fGTUqFESEREhLVu2fOglkG3N19/fX4YMGSJbtmyRgQMHytNPPy1//vmn/Pbbb3L69OkC59u6dWvp2rWrzJw5U4YMGSJOTk7i5uYmI0aMsJhgyL104FG0aivaqlUr0el04uHhIcuWLVO25z7HpSDPD82bN5fw8HA5d+6c/Pnnn/Laa6/l24LN1vjNmzeXiIgISU1NlfT0dAkNDZVVq1bJgAEDZNSoUbJ582bl57f2fjCZTJKWliaDBw+WadOmSWhoqNjZ2cnw4cPl9OnT0qxZM6Ubla35+vj4yIQJE0QkpwvSmDFjpE6dOlK1alUJCwuzmLiw5XHr16+f8onoli1bpEOHDlKuXDmpVauWtG3bVqZNm2YxSVAUWEST0jKpTp06Ur58eYmIiJDTp0/b9OSXn08//VTq1Klj8Q4x98kw5l/63GtZrbF48WKpV6+eUuwnJydLmzZtJDg4WOrUqSNt27a1mMmxxcmTJ6Vt27Zy48YNOX78uLz11ltSvXp1cXFxkf/85z9y6dIlm2POmTNHvLy8RCTnCaRv377i6ekpBoNBvL29pUePHg99wXyYM2fOiL+/v3LZUz8/P3nhhRfk1VdflSFDhkjNmjVl3LhxcvfuXZuetGbPni01a9YUk8kkSUlJ0qVLF3Fzc5PY2Fib8nvQN998I/Xr17cotnx9faVFixZSv3598fDwkD59+si1a9dsyvfSpUsSGBgo3333nYjcf8Hu0qWLzJw5U8aNGydVq1bNt4i0lhYtH7/++mvR6XRiMBikbt268uWXX+Yplk0mk81v2D7//HOpWbOmctb7H3/8Ic2aNVO6IuRejmKLlStXSs2aNZUWZUeOHJHQ0FAZPny4NGnSRHr37i07duywKabZsWPHpGvXrvLtt99KUFCQeHl5yTvvvCPDhg0TLy8v5T6w5fdi2bJl4u7urtwODw+XevXqib29vVSrVk3Cw8Pl6tWrNuf6008/iY+Pj1IkdujQQVq3bi1NmzaVjh07ip+fnyxZskRMJpPN+VatWlWysrLk1KlTUr9+fWnRooXyONpaMJl999134uXlpTwHp6enS9u2baVjx45Su3Zt8fX1lalTp8qdO3dsiv3NN9+It7e3xXP722+/Lb6+vvLMM89I//79C9QmT4u2ot9//700btxYvvzyS3n77bfFyclJWrRoYXHhJZGcJURHjhyx+n6Ijo6WevXqWXzScfToUXF3d5eYmBhlm61vTr777jupV6+exZvrJk2aSP369eXVV1+VJk2aiLu7u8UbNmuYf65FixZJz549RSRnGVytWrWkXLlyYjAYJC4uzubnhtWrV4ter1fuhzZt2sgLL7wg06dPl0WLFkn16tXF19fX5k4cIiITJkxQivMmTZrIO++8I7///rucPn1a3nrrLalbt65yXlVRYRFN8tprrykzK0uXLhUXFxfx8vKSRYsWyeXLl0UkZyZn4sSJysd1j2IymaRLly4ye/Zs5ftFRKKiosTb29viD/Xbb79VPhq2Jm5QUJBFa7lly5ZJuXLl5NNPP5XNmzfL4MGDpXbt2gVuc/P6668r6xLv3bsn9vb28vTTT0tAQIC89NJLVn/cKZJTrNSsWVOee+45ERGZOXOmtGnTRjmreOPGjdK4cWNp06aN3Llzx+onsMzMTPH19ZWYmBj55ptvpHXr1kqHDPO6T29vbzl+/LjVuWZmZoqjo6PFUp179+5J586dpXPnzkqhaC5UbXnRXbFihTRv3lz5fVqxYoVUqFBB9u/fL7/++qusW7dOatasWaAnxC5dusjIkSOV24cOHRI7OzvlBb5BgwayYMECm+Pmzl3tlo8DBw6UsLAwOXfunIwaNUrKlCkjQUFBFsudsrOzZdmyZTa9AQgKClL+5sy5fPjhh+Lv72+x7dixY/l+4vQwbdu2VeKKiKxatUrs7e3l7bfflvnz54u/v78EBgYqM4i2yMrKkueff17++9//ikjOm++nnnpK7O3tpVevXnL69Gmbi8eaNWtKnz59RETkk08+kZYtW8r8+fPl5s2bMnfuXHF2dpb+/fuLiG2/xzdv3hRfX185e/asrFq1Spo3b648dx07dkzCwsLEz8/P5gLd2dlZoqKilNu//vqr+Pr6yj//+U/lubMgM22zZs2SoKAgZYnC2rVrxd7eXlatWiXbt2+XKVOmSN26dZWPy60VGRkpPXv2lKysLOXv7Ouvv5Zu3brJ6tWrxdnZWfnkrajbin777bcyYsQI+eWXX0Qk5/nh5ZdfVq6eZy7ugoODZfz48VbHnTFjhnTt2lX5nTf/nK1bt5Z///vfyriXXnop37XCDxMZGSnjxo1T/j6//vprcXBwsPhUxtfXV3nNtlV2drZ07txZjhw5otx2dHQUe3t7ad68uSxbtsymJS0DBw4UDw8Pef/992XAgAHSvHlzizcWSUlJUrVqVVm6dKnNuc6ePVvatGkje/bskfbt2yuvH2bdunVT/o6LCovoUi4zM1M2bNggq1atUrZlZ2fLqFGjRKfTSbt27WTLli2yaNEisbe3t7qV2e3bt6VPnz4yffp0i+2///671KhRQ1nSER0dLfb29lavZ7p9+7bMnz/f4l24u7u7xQv8L7/8It7e3hYFiTXMT4Lr168Xb29vERF5+eWXpUuXLpKRkSGLFy+Wzp0721R8pKamyttvvy1t27aVxo0bS/ny5S2WLojkrOmtVq2a1e/UzS/6Q4YMkdDQUImIiLAoIkVyzoxu1aqVxeP6KGfPnlWKQZH7M0Fbt26VatWqycCBA62O9aBTp05JgwYNZNiwYRIRESEuLi4WLzRGo1GeffbZPL8vf8d8P3z66aei0+mkU6dO0rNnT6latarSNSUtLU169eqlzGYUNHc1Wz6mpKTI/PnzlQvCiOQUYOaT0oYPHy4XL16UdevWiaOjo9VtoBITE+W5556TuXPnWmw/evSo1KhRQ1mGtWfPHnF2drY4GfXvXLhwQcaOHWvx9+Th4SEffPCB8jcTGxtbqBn/2NhYefHFF5XH9JVXXpEaNWpIrVq1pH379rJixQqbLpfdsWNHeeaZZ6Rnz57i6uqap5/y//3f/0n16tVtvlhJWlqadO7cWd566y2ZNGlSnn7jFy9elLp16yrnUlhjzZo14uPjo9w2d9xZuHChODo6yr/+9S+bcsxtz549Urt2bZkzZ47SFSl3vCtXrkjjxo2VNzDWWrVqlXh5eVnMNpuXNojktGts0aKF1fG0bIGakZGR55O027dvy/r166V58+ZSrlw56dGjh+h0OptmuU+fPp1vQR8ZGSmdO3cWEZG9e/eKTqezepJIJOd3LHfB/MknnyjPPZmZmWIymWT06NHy+uuv2/zGKne7R/MVBQcMGCBBQUFy7do1+cc//iF6vd7q5wYRkTt37sjs2bMlICBAqlatarFcxmQyye3bt6Vr1655zoGxxsWLF6VRo0by0ksvSf369SU6Otpi/6JFi6RTp04FvnqnGlhEk0XLm9y/jOfOnVPOANbpdDJ16lSb4mZlZeU7e9epUyel6G3YsKFMmjSpUPkeOHBAeXLIysqSK1euSPPmzWXz5s02xc1txIgR8vrrr0vZsmUtWjXZUkDnzvfYsWMybNgw6devn3KCjMj9k5yaNGli8RGgNX799VcJCAiQ2rVrS+3atS0KmIyMDPH19S3wspYHbdu2TapXry6RkZEFOvvZZDLJ//73P3n++eflrbfekq5du8rHH39skW/Tpk1tfjE3O3r0qLz88ssycOBA+fTTT5XtmZmZ0rhx4wJdPEJEu5aPqampygtV7hfCb775RurVqydVq1aV8uXL2zzbdOTIEWWpQe7HqWnTprJ27VoRySl2wsLCbIprbhEoknMCaFRUlKSlpYnJZJKsrCw5d+6c+Pv721Q8mmVmZsrdu3elbdu2snbtWklISJAyZcrIyZMn5cyZM9K+fXuZP3++TTGvXLkic+fOlWeeeUZefPFFZRmW+T754YcfxM/Pz2KNrbXWrl0rXl5e0qhRI/H397eYdUtPT5dmzZpZfbKtmXmZ04N/W7Nnz5batWsrb4Zt+dszmUxy48YNGTJkiDRo0ED69esn/v7+FudLZGRkKLOPtvj999/F19dXPDw8ZPjw4RIUFCQeHh7Kz7Fhwwbx9/e3OF/AWmq3QM3twaIzOTlZOefF1jcrD1tPfejQIalZs6bcvn3bYv28NfJ7fPNbatO6dWubZrcfjH3x4kXp2rWrLFu2TOzt7WXPnj3KPluWXeT+uc+dOyczZ87M82l1dna2tGrVSjk3xdZ8zctxdDqdvPzyy/Ljjz/Kn3/+KcnJycpJtkWJRTTlkZ2dbTHT1rt3b2nYsGGh45r/KN5991155ZVXlHWAaps9e7bUr1+/UDHWr18vDg4OyhPgg/2YCyI9PV1pMZXbnDlzLGaibJGSkiL9+vUTnU6nfOS+Zs0aef3116V27dqFyldElLWd9+7dk0mTJomTk1OB+4OL3J/BnTVrlrz88sty/vx5OXnypHz44Yeq5Jt7HWVSUpJMnDhRPD09Cx1XRN2Wj38nIyNDnnvuOVXuD/Pv7JAhQ2T06NHy7bffisFgKHTcB89jWLp0qdSrV69AsczPC1988YV0795dfH19pV+/fqq0qjpx4oSsX7/eYi2+SM6FlBo1alTguF9++aV4enqKTqeToUOHyvbt2+Xw4cPywQcfiJubm83xHvxZc7fk69Gjh7i7u1t0LrGVeSnDuHHjZNSoUSKSc1Lk4sWLC5Sv+fsjIyOlRYsW8u6771qcZLxw4UKbXjO0aIH6YNyHmTp1qri6uqoSNzMzU/78809p3ry5dOvWrdBxH1wLn56eLosXL7b5dTO/fKdMmSI6nU5ee+01Ecn5nbP1NS6/k/pyPzekp6fLkiVLbGqDml/c8+fPyzvvvCMuLi7i5uamnEvTrl07m+JqgUU0PVR2dracOXNGdDqdMoulhu+//15cXV1Fp9NZ3SrPGhkZGbJ//37x8PCwaDNUUD/++KPFyWRqy8jIkL1794qbm1uh8z19+rQEBweLn5+flC1bVgYOHGjzchZrvPzyy8pFZwrj+vXr0qhRI6lXr55Ur15d/P39Zfv27SpkeN++ffvkjTfeKFDRr0XLx4fFfNCFCxdEr9dbrJF9VNyHrcE1vwiZZ0/Lli1r9Wx/fvk+WOyZTCY5ceKEeHp6ymeffVbguCI5L5xBQUFSp04dpWC05aRja+5fc741atQodL5Xr16V8PBwcXZ2loYNG4q9vb0EBwdbXPCpsPmK3D//4X//+1+h427cuFF0Op0EBARI8+bNpWHDhlY/B1t7/x45ckSqVq1q1f2rVQvUv4ubW0pKigQFBVn9u2Bt3NDQUJteN62JazKZ5JNPPpG6devKV199Vei4v/76q0ydOrVAJ8tbm+/cuXPFw8PD6mWFfxfXZDLJtWvXZM6cOTJjxgzZuHFjnjXSRYFFNP2tn376yaaTLayRmpoqLi4u0qZNG1XjXr58WV5++WV5/fXXVY2rld9//126dOkigwYNUi3mH3/8IVevXi10Z5UHmYsxWy9F/ndMJpPs27dPPv/8c5vaJtoSv6CXf9Wi5WPumA/OjOa2ZcsWi7XpasQ1vxm2ZZ2qNXHj4uIkODhYunfvrkrc2NhYi/7HtsyMWZPv4cOHpW3bttK1a1fV4v7xxx+ybds2iY2Nten3zZp8zW8icreiK2zc06dPy/Dhw2XixIkWH+PbEvdhy9oSExPlgw8+sPo5WKsWqPnFffDS0yI5b1Bs6XJhbdx9+/Yp7RXVipueni5xcXEWy3EKGzf3m1RbPvmxNt/Y2FhZvnx5oeLm9/vwuC+o8ndYRNMjadF/MT09/ZH9cQsiKyvrbwuU4iYzM9PiCnBU9LRo+fiwmA+2sDMfw9q199bGFclZ127+WF+tuCaTSRITE/Nc0KSwcW09UciWfM+fP2/1hS+sjWvrc2RR3w+2siVuZmamVb+/WrVAfVTcgrYLtDauOW9rny+sjWurR8W19X4t6nwL2p5TayyiiYhy0aLlozUxTSaTTJw40eor0VkbNysrSyZMmGDT8h5r4mZnZ8uECRNsmsn7u7i5T/6bOHGi7N+/X5N8c58orEbcrKwsmThxYr4zZoWJa74f1I6bmZkpEyZMUD2u+f615vdXyxaotsS1tr+7LXG/+eYbq7t82BpXq3y1uH+LQ9zHgUU0EdFftGj5qFUbSWvjLly48ImKq/X9YG37rqLOtyTH1bIFKuMy7uPEIpqIKBctWj5q1UaScRn3SY2rVQtUxmXcx0knIgIiIsqXyWSCyWRCmTJlAAB9+vTBzz//jNOnTxermIzLuE9yXBGBTqfDe++9h/Pnz6Njx46YNGkSrl27VqhcGZdxNVVk5TsR0RNEi5aPWrWRZFzGfVLjatUClXEZVwssoomIrKRFy0ctYjIu4z6pcbVqgcq4jKsFLucgIrKByWSCXq8v9jEZl3Gf1LgZGRkwGo2oUqWKajEZl3G1wCKaiIiIiMhG6r8lJSIiIiIq4VhEExERERHZiEU0EREREZGNWEQTEREREdmIRTQRERERkY1YRBMRERER2YhFNBFRCRcTEwM7OzuEhoYWdSo2efbZZzF27NiiToOIKF8soomISrjly5dj9OjR2L9/P65cuVLU6RARlQgsoomISrDbt29jzZo1GDlyJEJDQxEVFaXs27t3L3Q6HbZt24bmzZvDyckJzz33HK5du4YtW7agUaNGMBgMePXVV3H37l3l+9LT0/Hmm2+iWrVqKFu2LNq1a4fDhw8r+6OiouDq6mqRx3fffQedTqfcnjJlCpo1a4b/+7//g5eXF1xcXNC3b1/cunULADB48GDs27cP8+bNg06ng06nw2+//abJfUREVBAsoomISrC1a9eiYcOGaNCgAfr3748VK1bgwQvVTpkyBQsWLMDBgwdx6dIl9O7dG3PnzsWqVasQHR2N7du345NPPlHGR0RE4JtvvsHKlStx9OhR1KtXDyEhIbhx44ZNuZ07dw7fffcdNm3ahE2bNmHfvn2YMWMGAGDevHkIDAzEiBEjcPXqVVy9ehWenp6Fv0OIiFTCIpqIqARbvnw5+vfvDwDo0qULUlNTsW/fPosxH374Idq2bYvmzZtj2LBh2LdvHxYvXozmzZvjmWeewT/+8Q/s2bMHAHDnzh0sXrwYs2bNQteuXeHj44P//ve/cHJywvLly23KzWQyISoqCk2aNMEzzzyDAQMGYNeuXQAAFxcXODg4oFy5cnB3d4e7uzvs7OxUuEeIiNTBIpqIqIRKSEhAbGwsXnnlFQBAmTJl0KdPnzzFbtOmTZX/u7m5oVy5cqhTp47FtmvXrgHImT3OzMxE27Ztlf329vZo1aoVTp8+bVN+Xl5eqFChgnK7evXqynGIiIq7MkWdABERaWP58uXIysqCh4eHsk1E4OjoiAULFijb7O3tlf/rdDqL2+ZtJpPJ6uPq9fo8S0YyMzPzjCvscYiIihJnoomISqCsrCx8/vnn+PjjjxEfH698/fTTT/Dw8MDq1asLFLdu3bpwcHDAgQMHlG2ZmZk4fPgwfHx8AABVq1bFrVu3cOfOHWVMfHy8zcdycHBAdnZ2gfIkItIaZ6KJiEqgTZs24ebNmxg2bBhcXFws9vXs2RPLly/HrFmzbI5bvnx5jBw5EuPHj0elSpVQq1YtzJw5E3fv3sWwYcMAAAEBAShXrhzeeecdvPnmmzh06JBFVxBreXl54dChQ/jtt9/g7OyMSpUqQa/n3A8RFQ98NiIiKoGWL1+O4ODgPAU0kFNEHzlyBD///HOBYs+YMQM9e/bEgAED0KJFC5w9exbbtm1DxYoVAQCVKlXCF198gc2bN8PX1xerV6/GlClTbD7O22+/DTs7O/j4+KBq1apITEwsUL5ERFrQyYML14iIiIiI6G9xJpqIiIiIyEYsoomIiIiIbMQimoiIiIjIRiyiiYiIiIhsxCKaiIiIiMhGLKKJiIiIiGzEIpqIiIiIyEYsoomIiIiIbMQimoiIiIjIRiyiiYiIiIhsxCKaiIiIiMhGLKKJiIiIiGz0/7QeT4genBKqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.xticks(range(0, 30000, 1000), rotation=60)\n",
    "sns.histplot(card_df['Amount'], bins=100, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28bfc046-d303-479f-ab4d-f5fe3a96ccae",
   "metadata": {},
   "source": [
    "카드 사용 금액이 1000불 이하인 데이터가 대부분인 것이 한눈에 확인된다. Amount를 표준 정규 분포 형태로 변한한 뒤에 로지스틱 회귀의 예측 성능을 측정해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "86cc8414-95b1-411b-a13e-f164c9c076d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화 하기\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "card_df['Amount'] = scaler.fit_transform(card_df['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "360236b0-f970-41f2-afef-be04ec929be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.36224270928423"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_df['Amount'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a47dcafb-6861-49a6-8f65-65d565183112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3532293929668236"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_df['Amount'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7fcd847a-a1b1-4392-b22a-9ce3a8aa8d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균\n",
      "-1.5966860045099457e-17\n",
      "분산\n",
      "1.000003511161984\n"
     ]
    }
   ],
   "source": [
    "# 표준화 결과 평균이 0-분산이 1에 가까운 정규 분포형태가 되었는지 확인\n",
    "print(f\"평균\\n{card_df['Amount'].mean()}\")\n",
    "print(f\"분산\\n{card_df['Amount'].var()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e56aeba2-4253-4386-98f6-e4f4eb87c982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 예측\n",
      "오차 행렬\n",
      "[[85281    14]\n",
      " [   57    91]] \n",
      "\n",
      "정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702\n",
      "\n",
      "LightGBM 예측 성능\n",
      "오차 행렬\n",
      "[[85290     5]\n",
      " [   36   112]] \n",
      "\n",
      "정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790\n"
     ]
    }
   ],
   "source": [
    "# 데이터 셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_lables, test_size=0.3, random_state=0, stratify=y_lables)\n",
    "\n",
    "# 로지스틱 회귀 예측\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]\n",
    "# 평가\n",
    "print('로지스틱 회귀 예측')\n",
    "get_clf_eval(y_test, preds, lr_pred_proba)\n",
    "\n",
    "\n",
    "# LightGBM 예측 성능\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "preds = lgbm_clf.predict(X_test)\n",
    "lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]\n",
    "# 평가\n",
    "print('\\nLightGBM 예측 성능')\n",
    "get_clf_eval(y_test, preds, lgbm_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39386472-b1fb-4e99-8122-39f2c58554d6",
   "metadata": {},
   "source": [
    "변환 전 수치\n",
    "```\n",
    "로지스틱 회귀 예측\n",
    "[정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702]\n",
    "LightGBM 예측 성능\n",
    "[정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790]\n",
    "```\n",
    "위와 같았음으로 정말 큰차이가 안보이는 것을 확인할 수 있다. ~~안보이는 정도가 아니라 값이 같다~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb9880-8be5-4fac-a3f2-e7872e5d9b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e927be0a-03df-49e9-a8f7-a52cc4fb4f26",
   "metadata": {},
   "source": [
    "## 로그 변환 후 적용\n",
    "\n",
    "로그 변환은 데이터 분포도가 심하게 왜곡 되어있을 경우 적용하는 중요 기법 중 하나. 원래 값을 log값으로 변환해 작은 값으로 변환하기 때문에 데이터 분포도의 왜곡을 상당 수준 개선해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f8ab7a9e-2881-485d-a28d-96625abff13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_df_log = pd.read_csv(\"./creditcard.csv/creditcard.csv\")\n",
    "card_df_log.drop(['Time'], axis=1, inplace=True)\n",
    "card_df_log[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9bd0bac3-c66d-4361-9791-e24280b66f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log 변환하기\n",
    "# numpy 의 log1p()함수를 이용해 변환해보자\n",
    "card_df_log['Amount'] = np.log1p(card_df_log['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8dea5682-4930-49db-ac62-6559fe61cf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 예측\n",
      "오차 행렬\n",
      "[[85283    12]\n",
      " [   59    89]] \n",
      "\n",
      "정확도: 0.9992, 정밀도: 0.8812, 재현율: 0.6014,    F1: 0.7149, AUC:0.9727\n",
      "\n",
      "LightGBM 예측 성능\n",
      "오차 행렬\n",
      "[[85290     5]\n",
      " [   36   112]] \n",
      "\n",
      "정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790\n"
     ]
    }
   ],
   "source": [
    "# 데이터 셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_features = card_df_log.iloc[:,:-1]\n",
    "y_lables = card_df_log.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_lables, test_size=0.3, random_state=0, stratify=y_lables)\n",
    "\n",
    "# 로지스틱 회귀 예측\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]\n",
    "# 평가\n",
    "print('로지스틱 회귀 예측')\n",
    "get_clf_eval(y_test, preds, lr_pred_proba)\n",
    "\n",
    "\n",
    "# LightGBM 예측 성능\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "preds = lgbm_clf.predict(X_test)\n",
    "lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]\n",
    "# 평가\n",
    "print('\\nLightGBM 예측 성능')\n",
    "get_clf_eval(y_test, preds, lgbm_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c8899-2d5c-4b99-8f08-cbc1f8694526",
   "metadata": {},
   "source": [
    "변환 전 수치\n",
    "```\n",
    "로지스틱 회귀 예측\n",
    "[정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702]\n",
    "LightGBM 예측 성능\n",
    "[정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790]\n",
    "```\n",
    "로지스틱의 경우 정밀도와 AUC는 조금 향상되었으나 재현율은 저하된 모습.\n",
    "LightGBM의 경우는 변환전과 후가 같은 결과를 보이고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aa15d3-51a0-44d4-862a-6d41edbecc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64c5acc9-7f8a-4bb0-b308-a732eb55b1db",
   "metadata": {},
   "source": [
    "## 이상치 제거 후 적용\n",
    "이상치를 찾는 방법은 여러가지가 있지만 이중에서 IQR(Inter Quantile Range) 방식을 적용한다. 모든 피처들의 이상치를 검출한느 것은 시간이 많이 소모되며, 결정값과 상관성이 높지 않은 피처들의 경우는 이상치를 제거하더라고 크게 성능 향상에 기여하지 않기 때문에 결정값(즉 레이블)과 가장 상관성이 높은 피처들을 위추로 이상치를 검출하는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "189cad9b-9575-458e-95f9-d921b1752951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_df_iqr = pd.read_csv(\"./creditcard.csv/creditcard.csv\")\n",
    "card_df_iqr.drop(['Time'], axis=1, inplace=True)\n",
    "card_df_iqr[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a1735457-bcc0-4df5-ad89-58066815001c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DataFrame의 corr()을 이용해 각 피처별로 상관도를 구한 뒤 heatmap 시각화\n",
    "# 양이 상관도가 높을수록 파란색에 가까우며, 음의 상관관계가 높을 수록 붉은 색에 가깝다.\n",
    "corr_M = card_df_iqr.corr()\n",
    "sns.heatmap(corr_M, cmap=\"RdBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe87fe-8aca-4e49-bb3a-1ce0ccc08657",
   "metadata": {},
   "source": [
    "히트맵을 보면 음의 상관관계가 가장 높은 것이 v14와 v17로 나왔고 이중 v14에 대해서만 이상치를 찾아 제거해보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ad82cd5e-3ab5-48e5-b45e-b656c5a4af90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279863</th>\n",
       "      <td>-1.927883</td>\n",
       "      <td>1.125653</td>\n",
       "      <td>-4.518331</td>\n",
       "      <td>1.749293</td>\n",
       "      <td>-1.566487</td>\n",
       "      <td>-2.010494</td>\n",
       "      <td>-0.882850</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>-2.064945</td>\n",
       "      <td>-5.587794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778584</td>\n",
       "      <td>-0.319189</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>-0.294885</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.788395</td>\n",
       "      <td>0.292680</td>\n",
       "      <td>0.147968</td>\n",
       "      <td>390.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280143</th>\n",
       "      <td>1.378559</td>\n",
       "      <td>1.289381</td>\n",
       "      <td>-5.004247</td>\n",
       "      <td>1.411850</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-1.326536</td>\n",
       "      <td>-1.413170</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>-1.127396</td>\n",
       "      <td>-3.232153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.145640</td>\n",
       "      <td>-0.081049</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.739467</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.186637</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280149</th>\n",
       "      <td>-0.676143</td>\n",
       "      <td>1.126366</td>\n",
       "      <td>-2.213700</td>\n",
       "      <td>0.468308</td>\n",
       "      <td>-1.120541</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-2.234739</td>\n",
       "      <td>1.210158</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>-3.463891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.834108</td>\n",
       "      <td>0.190944</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>-0.739695</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>0.385107</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>77.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281144</th>\n",
       "      <td>-3.113832</td>\n",
       "      <td>0.585864</td>\n",
       "      <td>-5.399730</td>\n",
       "      <td>1.817092</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>-2.943548</td>\n",
       "      <td>-2.208002</td>\n",
       "      <td>1.058733</td>\n",
       "      <td>-1.632333</td>\n",
       "      <td>-5.245984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>-0.269209</td>\n",
       "      <td>-0.456108</td>\n",
       "      <td>-0.183659</td>\n",
       "      <td>-0.328168</td>\n",
       "      <td>0.606116</td>\n",
       "      <td>0.884876</td>\n",
       "      <td>-0.253700</td>\n",
       "      <td>245.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281674</th>\n",
       "      <td>1.991976</td>\n",
       "      <td>0.158476</td>\n",
       "      <td>-2.583441</td>\n",
       "      <td>0.408670</td>\n",
       "      <td>1.151147</td>\n",
       "      <td>-0.096695</td>\n",
       "      <td>0.223050</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>0.577829</td>\n",
       "      <td>-0.888722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164350</td>\n",
       "      <td>-0.295135</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.450261</td>\n",
       "      <td>0.313267</td>\n",
       "      <td>-0.289617</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>42.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "541    -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "623    -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "4920   -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "6108   -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "6329    1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "279863 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494 -0.882850   \n",
       "280143  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536 -1.413170   \n",
       "280149 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346 -2.234739   \n",
       "281144 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548 -2.208002   \n",
       "281674  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695  0.223050   \n",
       "\n",
       "              V8        V9       V10  ...       V21       V22       V23  \\\n",
       "541     1.391657 -2.770089 -2.772272  ...  0.517232 -0.035049 -0.465211   \n",
       "623    -0.067794 -0.270953 -0.838587  ...  0.661696  0.435477  1.375966   \n",
       "4920   -0.399147 -0.238253 -1.525412  ... -0.294166 -0.932391  0.172726   \n",
       "6108   -0.248778 -0.247768 -4.801637  ...  0.573574  0.176968 -0.436207   \n",
       "6329   -0.496358 -1.282858 -2.447469  ... -0.379068 -0.704181 -0.656805   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "279863  0.697211 -2.064945 -5.587794  ...  0.778584 -0.319189  0.639419   \n",
       "280143  0.248525 -1.127396 -3.232153  ...  0.370612  0.028234 -0.145640   \n",
       "280149  1.210158 -0.652250 -3.463891  ...  0.751826  0.834108  0.190944   \n",
       "281144  1.058733 -1.632333 -5.245984  ...  0.583276 -0.269209 -0.456108   \n",
       "281674 -0.068384  0.577829 -0.888722  ... -0.164350 -0.295135 -0.072173   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "541     0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "623    -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "4920   -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "6108   -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "6329   -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "279863 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00      1  \n",
       "280143 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76      1  \n",
       "280149  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89      1  \n",
       "281144 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00      1  \n",
       "281674 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53      1  \n",
       "\n",
       "[492 rows x 30 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class 가 1인 경우에만 진행할 것이기 때문에 솎아준다.\n",
    "fraud = card_df_iqr[card_df_iqr['Class'] == 1]\n",
    "fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bb3390-3a6f-420e-bdb8-b34519b828e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45f52c-d36a-444c-94dd-dbf61bf43e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45139b-88a8-40f7-a914-7b095476bf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99775191-2524-418e-a66e-d7c1bb086b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8876f7fb-0f21-4400-8677-d911c3178e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.409902115485521"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 넘파이 함수를 이용해 1/4분위와 3/4분위를 구하고, 이에 기반하여 IQR을 계산한다.\n",
    "Q_25 = np.percentile(fraud.V14, 25)\n",
    "Q_75 = np.percentile(fraud.V14, 75)\n",
    "IQR = Q_75 -Q_25\n",
    "IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "45c7dfdb-cff3-4c21-9c0b-b33c042d47d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.409902115485521"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 또 다르게 IQR 계산하기\n",
    "Q_25 = fraud['V14'].quantile(.25)\n",
    "Q_75 = fraud['V14'].quantile(.75)\n",
    "IQR = Q_75 - Q_25\n",
    "IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f488309d-fc33-4c1a-9a89-2a03b3c933f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8296   -19.214325\n",
       "8615   -18.822087\n",
       "9035   -18.493773\n",
       "9252   -18.049998\n",
       "Name: V14, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 구해진 IQR에 1.5를 곱해 최대값과 최소값 지점 구하기\n",
    "upper_out = Q_75 + 1.5 * IQR\n",
    "under_out = Q_25 - 1.5 * IQR\n",
    "\n",
    "# 이상치 데이터 검색 \n",
    "cond1 = fraud['V14'] >= upper_out\n",
    "cond2 = fraud['V14'] <= under_out\n",
    "fraud.V14[cond1 | cond2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "885aeaa0-775e-483c-b7c7-147f72580f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([8296, 8615, 9035, 9252], dtype='int64')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이상치의 데이터 인덱스 담아주기\n",
    "temp = fraud.V14[cond1 | cond2].index\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0fbf5880-cebc-4af3-96aa-770fa5733263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_df_iqr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4f2b367e-69f7-452d-ad1e-75fef06a3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# card_df에서 이상치를 제거해주세요\n",
    "card_df_iqr.drop(labels = temp, axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "223f706f-36cb-4dd9-b2ca-144f14c5624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284803, 30)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_df_iqr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3427d743-91c9-4d98-b75c-cf97986d380f",
   "metadata": {},
   "source": [
    "제거 전 'shape (284807, 30)'에서 이상치 4개 제거하니 'shape (284803, 30)' 로 잘 사라진 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3078d990-6127-441c-8115-cde2185c31b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 예측\n",
      "오차 행렬\n",
      "[[85279    16]\n",
      " [   48    98]] \n",
      "\n",
      "정확도: 0.9993, 정밀도: 0.8596, 재현율: 0.6712,    F1: 0.7538, AUC:0.9739\n",
      "\n",
      "LightGBM 예측 성능\n",
      "오차 행렬\n",
      "[[85291     4]\n",
      " [   25   121]] \n",
      "\n",
      "정확도: 0.9997, 정밀도: 0.9680, 재현율: 0.8288,    F1: 0.8930, AUC:0.9791\n"
     ]
    }
   ],
   "source": [
    "# 데이터 셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_features = card_df_iqr.iloc[:,:-1]\n",
    "y_lables = card_df_iqr.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_lables, test_size=0.3, random_state=0, stratify=y_lables)\n",
    "\n",
    "# 로지스틱 회귀 예측\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]\n",
    "# 평가\n",
    "print('로지스틱 회귀 예측')\n",
    "get_clf_eval(y_test, preds, lr_pred_proba)\n",
    "\n",
    "\n",
    "# LightGBM 예측 성능\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "preds = lgbm_clf.predict(X_test)\n",
    "lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]\n",
    "# 평가\n",
    "print('\\nLightGBM 예측 성능')\n",
    "get_clf_eval(y_test, preds, lgbm_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b50c32-3385-4af6-8acb-fa94bb056e28",
   "metadata": {},
   "source": [
    "변환 전 수치\n",
    "```\n",
    "로지스틱 회귀 예측\n",
    "[정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702]\n",
    "LightGBM 예측 성능\n",
    "[정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790]\n",
    "```\n",
    "로지스틱의 경우 정확도와 재현율, f1, auc 가 향상 되었으나 정밀도는 조금 떨어진 모습\n",
    "LightGBM의 경우 5가지 모두 전반적으로 향상된 모습을 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559992d4-b4b3-4fb4-bff9-cfa68b63a016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688e8ef-a620-43de-8bb3-09f7f54ec5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad34a-d07b-4a5b-ac76-1e732c6a80a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aef0a424-9997-44f9-9a6a-968582f3f0e3",
   "metadata": {},
   "source": [
    "## log와 이상치 제거를 함께 한다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eeed1c37-0f34-4534-8583-a0550f8523e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# card_df_iqr 데이터에 log 적용\n",
    "card_df_iqr['Amount'] = np.log1p(card_df_iqr['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6337e795-9892-485a-9c1c-7fce3c786c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 예측\n",
      "오차 행렬\n",
      "[[85281    14]\n",
      " [   48    98]] \n",
      "\n",
      "정확도: 0.9993, 정밀도: 0.8750, 재현율: 0.6712,    F1: 0.7597, AUC:0.9743\n",
      "\n",
      "LightGBM 예측 성능\n",
      "오차 행렬\n",
      "[[85291     4]\n",
      " [   25   121]] \n",
      "\n",
      "정확도: 0.9997, 정밀도: 0.9680, 재현율: 0.8288,    F1: 0.8930, AUC:0.9791\n"
     ]
    }
   ],
   "source": [
    "# 데이터 셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_features = card_df_iqr.iloc[:,:-1]\n",
    "y_lables = card_df_iqr.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_lables, test_size=0.3, random_state=0, stratify=y_lables)\n",
    "\n",
    "# 로지스틱 회귀 예측\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]\n",
    "# 평가\n",
    "print('로지스틱 회귀 예측')\n",
    "get_clf_eval(y_test, preds, lr_pred_proba)\n",
    "\n",
    "\n",
    "# LightGBM 예측 성능\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "preds = lgbm_clf.predict(X_test)\n",
    "lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]\n",
    "# 평가\n",
    "print('\\nLightGBM 예측 성능')\n",
    "get_clf_eval(y_test, preds, lgbm_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d963956-8743-4a95-9820-c41ee1e5189d",
   "metadata": {},
   "source": [
    "이상치 제거만 했을 때는 아래와 같았다.\n",
    "```\n",
    "로지스틱 회귀 예측\n",
    "[정확도: 0.9993, 정밀도: 0.8596, 재현율: 0.6712,    F1: 0.7538, AUC:0.9739]\n",
    "\n",
    "LightGBM 예측 성능\n",
    "[정확도: 0.9997, 정밀도: 0.9680, 재현율: 0.8288,    F1: 0.8930, AUC:0.9791]\n",
    "```\n",
    "함께 했을 때.. 로지스틱의 경우 정밀도와 f1, auc가 향상되었다.\n",
    "LightGBM의 경우변화가 없는 모습.\n",
    "성능이 떨어지지는 않았으니 같이 하는 것이 나쁘지는 않은 선택같이 보이는 결과를 주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfda73e-3b3a-473d-8df1-99dca6888b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ec05b7b-e3fd-464d-98e5-e84226e06577",
   "metadata": {},
   "source": [
    "## SMOTE 오버 샘플링 적용\n",
    "SMOTE를 적용할 때에는 반드시 학습 데이터 셋만 오버 샘플링을 해야한다. 검증 데이터 셋이나 테스트 데이터 셋을 오버 샘플링할 경우 결국은 원본 데이터 세트가 아닌 데이터 세트에서 검증 또는 테스트를 수행하기 때문에 올바른 검증/테스트가 될수 없기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4308ab50-f8c8-48b9-8659-be1551da85a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.23.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# SMOTE를 구현한 대표적인 파이썬 패키지 설치\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c22e408c-239f-495c-819e-ce1620d18f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용전 학습용 피처/레이블 데이터 셋 : (199362, 29), (199362,)\n",
      "SMOTE 적용후 학습용 피처/레이블 데이터 셋 : (398040, 29), (398040,)\n",
      "SMOTE 적용후 레이블 값 분포 : \n",
      "0    199020\n",
      "1    199020\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 증식\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# test는 건드리면 안된다. 따라서 train만 건드리기\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(f'SMOTE 적용전 학습용 피처/레이블 데이터 셋 : {X_train.shape}, {y_train.shape}')\n",
    "print(f'SMOTE 적용후 학습용 피처/레이블 데이터 셋 : {X_train_smote.shape}, {y_train_smote.shape}')\n",
    "print(f'SMOTE 적용후 레이블 값 분포 : \\n{pd.Series(y_train_smote).value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ea2b5fd1-6f34-4a99-a46c-77ff1ff3cc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 예측\n",
      "오차 행렬\n",
      "[[85281    14]\n",
      " [   48    98]] \n",
      "\n",
      "정확도: 0.9993, 정밀도: 0.8750, 재현율: 0.6712,    F1: 0.7597, AUC:0.9743\n",
      "\n",
      "LightGBM 예측 성능\n",
      "오차 행렬\n",
      "[[85291     4]\n",
      " [   25   121]] \n",
      "\n",
      "정확도: 0.9997, 정밀도: 0.9680, 재현율: 0.8288,    F1: 0.8930, AUC:0.9791\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 예측\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "preds = lr_clf.predict(X_test)\n",
    "lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]\n",
    "# 평가\n",
    "print('로지스틱 회귀 예측')\n",
    "get_clf_eval(y_test, preds, lr_pred_proba)\n",
    "\n",
    "\n",
    "# LightGBM 예측 성능\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "preds = lgbm_clf.predict(X_test)\n",
    "lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]\n",
    "# 평가\n",
    "print('\\nLightGBM 예측 성능')\n",
    "get_clf_eval(y_test, preds, lgbm_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19980fe2-101d-47fc-b0be-92c986c823f6",
   "metadata": {},
   "source": [
    "SMOTE 이 전 수치\n",
    "```\n",
    "로지스틱 회귀 예측\n",
    "[정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702]\n",
    "LightGBM 예측 성능\n",
    "[정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790]\n",
    "```\n",
    "로지스틱의 경우 전체적으로 조금씩 향상된 모습\n",
    "LightGBM의 경우에도 전체적으로 조금씩 향상된 모습을 보였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6a456d4b-3a88-44ae-b915-02c5fe0a5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_train_eval(model, train_x=None, test_x=None, train_y=None, test_y=None):\n",
    "    model.fit(train_x, train_y)\n",
    "    pred = model.predict(test_x)\n",
    "    pred_proba = model.predict_proba(test_x)[:,1]\n",
    "    get_clf_eval(test_y, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bc48df40-e4fd-4edb-a231-1ce34b96219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM : boost_from_average=True 예측 성능\n",
      "오차 행렬\n",
      "[[85268    27]\n",
      " [   36   110]] \n",
      "\n",
      "정확도: 0.9993, 정밀도: 0.8029, 재현율: 0.7534,    F1: 0.7774, AUC:0.9219\n",
      "\n",
      "LightGBM 예측 성능\n",
      "오차 행렬\n",
      "[[85291     4]\n",
      " [   25   121]] \n",
      "\n",
      "정확도: 0.9997, 정밀도: 0.9680, 재현율: 0.8288,    F1: 0.8930, AUC:0.9791\n"
     ]
    }
   ],
   "source": [
    "print('LightGBM : boost_from_average=True 예측 성능')\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=True)\n",
    "get_model_train_eval(lgbm_clf, train_x=X_train, test_x=X_test, train_y=y_train, test_y=y_test)\n",
    "\n",
    "\n",
    "\n",
    "print('\\nLightGBM 예측 성능')\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, train_x=X_train, test_x=X_test, train_y=y_train, test_y=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3144f-cc13-4ea1-8de9-55619270d2b0",
   "metadata": {},
   "source": [
    "# 정말 옵션값만 True / False로 설정해줬을 뿐인데 모든 값에서 값이 떨어진 것을 확인할 수 있었다. 가중치 업데이트 시 평균값에서 시작하게 하는 옵션이라는데 데이터가 불균형하기 때문에 평균값도 올바르지 않아서(? 그런것일까...\n",
    "\n",
    "LightGBM 2.1.0 이상 버전에서 `boost_from_average` 파라미터 디폴트 값은 True이기 때문에 데이터 값이 불균형하면 False 로 꺼주는 것을 잊지 말자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cca71b74-b622-48ed-a04e-59c091964786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mboosting_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gbdt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnum_leaves\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msubsample_for_bin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mobjective\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_split_gain\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_child_weight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_child_samples\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msubsample\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msubsample_freq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreg_alpha\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreg_lambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msilent\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'warn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mimportance_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'split'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      LightGBM classifier.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Construct a gradient boosting model.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "boosting_type : str, optional (default='gbdt')\n",
       "    'gbdt', traditional Gradient Boosting Decision Tree.\n",
       "    'dart', Dropouts meet Multiple Additive Regression Trees.\n",
       "    'goss', Gradient-based One-Side Sampling.\n",
       "    'rf', Random Forest.\n",
       "num_leaves : int, optional (default=31)\n",
       "    Maximum tree leaves for base learners.\n",
       "max_depth : int, optional (default=-1)\n",
       "    Maximum tree depth for base learners, <=0 means no limit.\n",
       "learning_rate : float, optional (default=0.1)\n",
       "    Boosting learning rate.\n",
       "    You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
       "    in training using ``reset_parameter`` callback.\n",
       "    Note, that this will ignore the ``learning_rate`` argument in training.\n",
       "n_estimators : int, optional (default=100)\n",
       "    Number of boosted trees to fit.\n",
       "subsample_for_bin : int, optional (default=200000)\n",
       "    Number of samples for constructing bins.\n",
       "objective : str, callable or None, optional (default=None)\n",
       "    Specify the learning task and the corresponding learning objective or\n",
       "    a custom objective function to be used (see note below).\n",
       "    Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
       "class_weight : dict, 'balanced' or None, optional (default=None)\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    Use this parameter only for multi-class classification task;\n",
       "    for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
       "    Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
       "    You may want to consider performing probability calibration\n",
       "    (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
       "    The 'balanced' mode uses the values of y to automatically adjust weights\n",
       "    inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
       "    If None, all classes are supposed to have weight one.\n",
       "    Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
       "    if ``sample_weight`` is specified.\n",
       "min_split_gain : float, optional (default=0.)\n",
       "    Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
       "min_child_weight : float, optional (default=1e-3)\n",
       "    Minimum sum of instance weight (hessian) needed in a child (leaf).\n",
       "min_child_samples : int, optional (default=20)\n",
       "    Minimum number of data needed in a child (leaf).\n",
       "subsample : float, optional (default=1.)\n",
       "    Subsample ratio of the training instance.\n",
       "subsample_freq : int, optional (default=0)\n",
       "    Frequency of subsample, <=0 means no enable.\n",
       "colsample_bytree : float, optional (default=1.)\n",
       "    Subsample ratio of columns when constructing each tree.\n",
       "reg_alpha : float, optional (default=0.)\n",
       "    L1 regularization term on weights.\n",
       "reg_lambda : float, optional (default=0.)\n",
       "    L2 regularization term on weights.\n",
       "random_state : int, RandomState object or None, optional (default=None)\n",
       "    Random number seed.\n",
       "    If int, this number is used to seed the C++ code.\n",
       "    If RandomState object (numpy), a random integer is picked based on its state to seed the C++ code.\n",
       "    If None, default seeds in C++ code are used.\n",
       "n_jobs : int, optional (default=-1)\n",
       "    Number of parallel threads.\n",
       "silent : bool, optional (default=True)\n",
       "    Whether to print messages while running boosting.\n",
       "importance_type : str, optional (default='split')\n",
       "    The type of feature importance to be filled into ``feature_importances_``.\n",
       "    If 'split', result contains numbers of times the feature is used in a model.\n",
       "    If 'gain', result contains total gains of splits which use the feature.\n",
       "**kwargs\n",
       "    Other parameters for the model.\n",
       "    Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
       "\n",
       "    .. warning::\n",
       "\n",
       "        \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
       "\n",
       "Note\n",
       "----\n",
       "A custom objective function can be provided for the ``objective`` parameter.\n",
       "In this case, it should have the signature\n",
       "``objective(y_true, y_pred) -> grad, hess`` or\n",
       "``objective(y_true, y_pred, group) -> grad, hess``:\n",
       "\n",
       "    y_true : array-like of shape = [n_samples]\n",
       "        The target values.\n",
       "    y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The predicted values.\n",
       "        Predicted values are returned before any transformation,\n",
       "        e.g. they are raw margin instead of probability of positive class for binary task.\n",
       "    group : array-like\n",
       "        Group/query data.\n",
       "        Only used in the learning-to-rank task.\n",
       "        sum(group) = n_samples.\n",
       "        For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,\n",
       "        where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.\n",
       "    grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the first order derivative (gradient) of the loss\n",
       "        with respect to the elements of y_pred for each sample point.\n",
       "    hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the second order derivative (Hessian) of the loss\n",
       "        with respect to the elements of y_pred for each sample point.\n",
       "\n",
       "For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
       "If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
       "and you should group grad and hess in this way as well.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\lightgbm\\sklearn.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     DaskLGBMClassifier\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LGBMClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342d582-590e-4834-adc0-1814c8fa3b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d521f4-7d5e-4b73-bd57-5c2719d1a2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

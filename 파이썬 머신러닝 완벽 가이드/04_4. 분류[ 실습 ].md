위키북스의 '파이썬 머신러닝 완벅 가이드' 개정 2판으로 공부하고 있습니다. 실습 과정과 이해에 따라 내용의 누락 및 코드의 변형이 있을 수 있습니다.

----


## 분류 실습 - 캐글 산탄데르 고객 만족 예측
370개의 피처로 주어진 데이터 세트에 기반하여 고객 만족 여부를 예측한다. 피처 이름은 모두 익명처리 되어 이름만 가지고는 어떤 속성인지 추정할 수 없으며, 클래스 레이블 명은 Target. 이 값이 1이면 불만을 가진 고객 0이면 만족한 고객이다.

### 데이터 불러오기+전처리
[kaggle](https://www.kaggle.com/c/santander-customer-satisfaction/data)에서 받아온 데이터를 사용중인 폴더(Working directory)에 넣어준 후 불러왔다.

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib

cust_df = pd.read_csv("./santander_customer/train.csv")
print('dataset shape : ', cust_df.shape)
cust_df[:3]
```
![](https://velog.velcdn.com/images/cyhse7/post/828642a2-7e1b-4b22-a153-956695f7594a/image.png)
label로 사용할 TARGET 컬럼의 비율이 궁금하니 검색해보기로 한다
```python
cust_df.TARGET.value_counts()/len(cust_df)
>
0    0.960431
1    0.039569
Name: TARGET, dtype: float64
```
오홍... 굉장히 불균형하다. 대부분이 만족(0)이므로 정확도 보다는 `ROC-AUC`로 성능을 평가하기로 하고, `describe()`메서드를 이용해 각 피처의 값 분포를 확인해보면
```python
cust_df.describe()
```
![](https://velog.velcdn.com/images/cyhse7/post/8883220b-62d7-4967-adfe-220c1304dd97/image.png)
이와 같은데, var3을보면 min(최소값)에 갑자기 -999999 값이 튀어나온 모습을 확인할 수 있다. 이는 NaN이나 특정 예외 값을 이와 같이 변환했다고 생각해 볼 수 있으나, 다른 값에 비해 너무 편차가 크므로 해당 수를 replace하여 값이 가장 많은 2로 변환하기로 한다.
```python
cust_df['var3'] = cust_df['var3'].replace(-999999, 2)

# 변환 후 값 확인
cust_df['var3'].value_counts()
# 2      74281
# 8        138
# 9        110
# 3        108
# 1        105
#        ...  
# 231        1
# 188        1
# 168        1
# 135        1
# 87         1
# Name: var3, Length: 207, dtype: int64


cust_df['var3'].min()
# 0
```
ID는 지우고, Target은 label로 분리
```python
cust_df.drop(['ID'], axis=1, inplace = True)
X_features = cust_df.iloc[:,:-1]
y_label = cust_df.iloc[:, -1]

X_features.shape
# (76020, 369)
```
학습과 성능 평가를 위해 원본 데이터 set에서 train data set과 test data set를 분리한다. XGB의 조기 중단(early stopping)의 검증 데이터 셋으로 사용하기 위해 X_train, y_train을 쪼개서 학습과 검증 데이터 셋트로 한번 더 나눠준다.
```python
# train과 test 셋 나눠주기
X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size=0.2, random_state=11)

# 나눠준 train 데이터를 다시 학습과 검증 데이터로 분리
# 조기중단(early stopping)을 위하여
X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=11)
```
### XGB 모델 학습과 하이퍼 파라미터 튜닝
학습 모델을 생성하고 예측 결과를 ROC-AUC로 평가해보기로 한다. 따라서 XGBClassifier의 eval_metric는 'auc'로 설정(하지만 logloss로 해도 큰 차이는 없다고 한다.). 앞에서 분리한 학습과 검증 데이터 셋을 이용하여 조기 중단은 100회로 설정한다.
```python
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score

# n_estimators는 500으로, random state는 예제 수행 시마다 동일 예측 결과를 위해 설정
xgb_clf = XGBClassifier(n_estimators=500, learning_rate=0.05, random_state=156)

# 성능 평가 지표를 aux로, 조기 중단 파라미터는 100으로 설정하고 학습 수행
xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric='auc', eval_set=[(X_tr, y_tr), (X_val, y_val)])
```
![](https://velog.velcdn.com/images/cyhse7/post/6a3da205-05e8-46ed-a358-f2e5d85a81a0/image.gif)
![](https://velog.velcdn.com/images/cyhse7/post/542af43a-a6d4-4a88-a894-39a066ba1c37/image.png)

쭉 뽑혀나온다. 500번 학습을 설정하였으나 조기 중단으로 269까지만 한 모습을 확인할 수 있었다.
```python
# 테스트 데이터 셋으로 ROC-AUC 값 확인하기
xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])
print(f'ROC AUC : {xgb_roc_score}')
```
```
ROC AUC : 0.8326294708915177
```
예측
```python
preds = xgb_clf.predict(X_test)
accuracy_score(y_test, preds)
```
```
0.9606682451986319
```
예상 정확도가 약 96.0% 로 뽑혔다. 와우. HyperOpt를 이용하여 베이지안 최적화 기반으로 XGB의 하이퍼 파라미터 튜닝을 수행해보자.
### 검색 공간 설정
```python
# 하이퍼 파라미터 검색 공간 설정
                    # max_depth는 5에서 15까지 간격 1로
xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 15, 1), 
                    # min_child_weight는 1에서 6까지 간격 1로
                    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),
                    # colsample_bytree는 0.5에서 0.95사이
                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),
                    # learning_rate는 0.01에서 0.2사이 정규 분포된 값
                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)
                   }
```
### 목적함수 만들기
3 Fold 교차검능을 이용해 평균 ROC-AUC값을 반환하되 -1을 곱해주어 최대 ROC-AUC값이 최소 반환값이 되도록 한다.
```python
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score

# 목적 함수 설정. 
# 추후 fmin()에서 입력된 search_space값으로 XGBClassifier 교차 검증 학습 후 -1* roc_auc 평균 값을 반환.  
def objective_func(search_space):
    # 하이퍼 파라미터 검색 공간
    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth'])
                           , min_child_weight=int(search_space['min_child_weight'])
                            , colsample_bytree=search_space['colsample_bytree']
                            , learning_rate=search_space['learning_rate']
                           )
    
    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list
    roc_auc_list= []
    
    # 3개 k-fold방식 적용 
    kf = KFold(n_splits=3)
    # X_train을 다시 학습과 검증용 데이터로 분리
    for tr_index, val_index in kf.split(X_train):
        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리 
        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]
        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]
        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행.
        xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric='auc'
                   , eval_set=[(X_tr, y_tr), (X_val, y_val)])
    
        # 1로 예측한 확률값 추출후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값 담음. 
        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])
        roc_auc_list.append(score)
    
    # 3개 k-fold로 계산된 roc_auc값의 평균값을 반환하되, 
    # HyperOpt는 목적함수의 최소값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환. 
    return -1 * np.mean(roc_auc_list) 
```
### fmin()
`fmin()` 함수를 호출해 max_eval=50회 반복하며 최적의 하이퍼 파라미터를 도출하자. 50회만큼의 교차 검증이 반복되며 학습/평가를 하기 때문에 꽤 시간이 걸린다.
```python
from hyperopt import fmin, tpe, Trials

trials = Trials()

# fmin()함수를 호출, 목적함수의 최소값을 가지는 최적 입력값을 추출하자
best = fmin(fn=objective_func,
           space=xgb_search_space,
           algo=tpe.suggest,
           # 지정된 횟수만큼 반복
           max_evals=50,
           trials=trials, rstate=np.random.default_rng(seed=30)
           )
```
![](https://velog.velcdn.com/images/cyhse7/post/dc8140e3-3f34-4637-bb95-4a768dd09f69/image.gif)
정말 오래 걸린다. 한 30-40분 걸린듯
```
print('best : ', best)
>
.
.
.
.
best :  {'colsample_bytree': 0.5659263778337817, 'learning_rate': 0.09882594691417974, 'max_depth': 5.0, 'min_child_weight': 6.0}
```
도출된 최적 하이퍼 파라미터를 기반으로 XGBClassifier를 재학습시키고 데스트 데이터 셋에서 ROC-AUC를 측정해 보자.
```python
# n_estimators를 500으로 증가 후
# 찾아낸 최적 하이퍼 파라미터를 기반으로 학습/예측 수행
xgb_clf = XGBClassifier(n_estimators=500,
                          learning_rate=int(best['learning_rate']),
                          max_depth=int(best['max_depth']),
                          min_child_weight=int(best('min_child_weight')),
                          colsample_bytree=found(best['colsample_bytree'])
                        )
# evaluation metric을 하나의 auc로 하고
# 조기중단은 100으로 설정후 학습 수행
xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric='auc', eval_set=[(X_tr, y_tr), (X_val, y_val)])
xgb_roc_score=roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])
print(xgb_roc_score)
```
```
[0]	validation_0-auc:0.50000	validation_1-auc:0.50000
[1]	validation_0-auc:0.50000	validation_1-auc:0.50000
[2]	validation_0-auc:0.50000	validation_1-auc:0.50000
[3]	validation_0-auc:0.50000	validation_1-auc:0.50000
[4]	validation_0-auc:0.50000	validation_1-auc:0.50000
[5]	validation_0-auc:0.50000	validation_1-auc:0.50000
[6]	validation_0-auc:0.50000	validation_1-auc:0.50000
[7]	validation_0-auc:0.50000	validation_1-auc:0.50000
[8]	validation_0-auc:0.50000	validation_1-auc:0.50000
[9]	validation_0-auc:0.50000	validation_1-auc:0.50000
[10]	validation_0-auc:0.50000	validation_1-auc:0.50000
[11]	validation_0-auc:0.50000	validation_1-auc:0.50000
[12]	validation_0-auc:0.50000	validation_1-auc:0.50000
[13]	validation_0-auc:0.50000	validation_1-auc:0.50000
[14]	validation_0-auc:0.50000	validation_1-auc:0.50000
[15]	validation_0-auc:0.50000	validation_1-auc:0.50000
[16]	validation_0-auc:0.50000	validation_1-auc:0.50000
[17]	validation_0-auc:0.50000	validation_1-auc:0.50000
[18]	validation_0-auc:0.50000	validation_1-auc:0.50000
[19]	validation_0-auc:0.50000	validation_1-auc:0.50000
[20]	validation_0-auc:0.50000	validation_1-auc:0.50000
[21]	validation_0-auc:0.50000	validation_1-auc:0.50000
[22]	validation_0-auc:0.50000	validation_1-auc:0.50000
[23]	validation_0-auc:0.50000	validation_1-auc:0.50000
[24]	validation_0-auc:0.50000	validation_1-auc:0.50000
[25]	validation_0-auc:0.50000	validation_1-auc:0.50000
[26]	validation_0-auc:0.50000	validation_1-auc:0.50000
[27]	validation_0-auc:0.50000	validation_1-auc:0.50000
[28]	validation_0-auc:0.50000	validation_1-auc:0.50000
[29]	validation_0-auc:0.50000	validation_1-auc:0.50000
[30]	validation_0-auc:0.50000	validation_1-auc:0.50000
[31]	validation_0-auc:0.50000	validation_1-auc:0.50000
[32]	validation_0-auc:0.50000	validation_1-auc:0.50000
[33]	validation_0-auc:0.50000	validation_1-auc:0.50000
[34]	validation_0-auc:0.50000	validation_1-auc:0.50000
[35]	validation_0-auc:0.50000	validation_1-auc:0.50000
[36]	validation_0-auc:0.50000	validation_1-auc:0.50000
[37]	validation_0-auc:0.50000	validation_1-auc:0.50000
[38]	validation_0-auc:0.50000	validation_1-auc:0.50000
[39]	validation_0-auc:0.50000	validation_1-auc:0.50000
[40]	validation_0-auc:0.50000	validation_1-auc:0.50000
[41]	validation_0-auc:0.50000	validation_1-auc:0.50000
..
이하생략
```

```python
# 피처의 중요도를 시각화하여 보기
from xgboost import plot_importance
import matplotlib.pyplot as plt

fig, ax = plt.subplots(1, 1, figsize=(10, 8))
plot_importance(xgb_clf, ax=ax, max_num_features=20, height=0.4)
```
![](https://velog.velcdn.com/images/cyhse7/post/99d00680-1d38-4dfc-9bd8-78c0c6e60993/image.png)
LightGBM을 직접 수행해보면서 XGB보다는 학습에 걸리는 시간이 좀 더 단축되었음을 느낄 수 있었다. 
```python
# LightGBM 모델 학습과 하이퍼 파라미터 튜닝
from lightgbm import LGBMClassifier

lgbm_clf = LGBMClassifier(n_estimators=500)
eval_set=[(X_tr, y_tr), (X_val, y_val)]
lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric='auc', eval_set=eval_set)

lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1])
print(f'ROC-AUC : {lgbm_roc_score}')
```
```
[1]	training's auc: 0.830333	training's binary_logloss: 0.158262	valid_1's auc: 0.800033	valid_1's binary_logloss: 0.156656
[2]	training's auc: 0.835095	training's binary_logloss: 0.152432	valid_1's auc: 0.806471	valid_1's binary_logloss: 0.15186
[3]	training's auc: 0.84184	training's binary_logloss: 0.1482	valid_1's auc: 0.808535	valid_1's binary_logloss: 0.148619
[4]	training's auc: 0.847707	training's binary_logloss: 0.144867	valid_1's auc: 0.812339	valid_1's binary_logloss: 0.146112
[5]	training's auc: 0.852553	training's binary_logloss: 0.141937	valid_1's auc: 0.816928	valid_1's binary_logloss: 0.14387
[6]	training's auc: 0.854143	training's binary_logloss: 0.139571	valid_1's auc: 0.817505	valid_1's binary_logloss: 0.142262
[7]	training's auc: 0.857426	training's binary_logloss: 0.137489	valid_1's auc: 0.820769	valid_1's binary_logloss: 0.14087
[8]	training's auc: 0.862499	training's binary_logloss: 0.135785	valid_1's auc: 0.824541	valid_1's binary_logloss: 0.139729
[9]	training's auc: 0.864169	training's binary_logloss: 0.134334	valid_1's auc: 0.82638	valid_1's binary_logloss: 0.138841
..
이하 생략
```
목적함수 생성. 앞서 XGB와 목적함수가 크게 다르지는 않지만, LGBMClassifer 객체를 생성하는 부분이 다를 뿐이다.
```python
def objective_func(search_space):
    # 하이퍼 파라미터 검색 공간
    lgbm_clf = LGBMClassifier(n_estimators=100,
                              num_leaves=int(search_space['num_leaves']),
                              max_depth=int(search_space['max_depth']),
                              min_child_samples=int(search_space['min_child_samples']),
                              subsample=search_space['subsample']
                            , learning_rate=search_space['learning_rate']
                           )
    
    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list
    roc_auc_list= []
    
    # 3개 k-fold방식 적용 
    kf = KFold(n_splits=3)
    # X_train을 다시 학습과 검증용 데이터로 분리
    for tr_index, val_index in kf.split(X_train):
        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리 
        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]
        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]
        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행.
        xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric='auc'
                   , eval_set=[(X_tr, y_tr), (X_val, y_val)])
    
        # 1로 예측한 확률값 추출후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값 담음. 
        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])
        roc_auc_list.append(score)
    
    # 3개 k-fold로 계산된 roc_auc값의 평균값을 반환하되, 
    # HyperOpt는 목적함수의 최소값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환. 
    return -1 * np.mean(roc_auc_list) 
```
이제 HyperOpt를 이용하여 하이퍼 파라미터 튜닝을 수행할 것이다.

하이퍼 파라미터 검색 공간 설정
```python
lgbm_search_space = {
    'num_leaves':hp.quniform('num_leaves', 32, 64, 1),
    'max_depth' : hp.quniform('max_depth', 100, 160, 1),
    'min_child_samples':hp.quniform('min_child_samples', 60, 100, 1),
    'subsample' : hp.uniform('subsample', 0.7, 1),
    'learning_rate':hp.uniform('learning_rate', 0.01, 0.2)
    }
```
fmin()을 호출하여 최적 하이퍼 파라미터 도출
```python
import numpy as np
from hyperopt import fmin, tpe, Trials

# fmin()호출하여 최적 하이퍼파라미터를 도출
trials = Trials()

# fmin() 함수를 호출하고 max_evals 회수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출
best = fmin(fn=objective_func,
           space=lgbm_search_space,
           algo=tpe.suggest,
           max_evals=50,
           trials=trials,
           rstate=np.random.default_rng(seed=30))
print('best: ', best)
```
```
[0]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                  
[1]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                  
[2]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                  
[3]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                  
[4]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                  
[5]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                  
[6]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                  
[7]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                  
[8]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                  
[9]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                  
[10]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[11]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[12]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[13]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[14]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[15]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[16]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[17]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[18]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[19]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[20]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[21]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[22]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[23]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[24]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[25]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[26]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[27]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[28]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[29]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
[30]	validation_0-auc:0.50000	validation_1-auc:0.50000                                                                 
  0%|                                                                           | 0/50 [00:06<?, ?trial/s, best loss=?]
...
이하 생략

best:  {'learning_rate': 0.02347777899863792, 'max_depth': 134.0, 'min_child_samples': 75.0, 'num_leaves': 34.0, 'subsample': 0.7754775757159653}
```
출력된 하이퍼 파라미터를 이용하여 LightGBM학습 후 Test Data Set에서 ROC-AUC를 평가해본다
```python
lgbm_clf = LGBMClassifier(n_estimators=500,
                          num_leaves=int(best['num_leaves']),
                          max_dept=int(best['max_depth']),
                          min_child_samples=int(best['min_child_samples']),
                          subsample=round(best['subsample'], 5),
                          learning_rate=round(best['learning_rate'], 5)
                        )

# evaluation metric를 auc로, early stopping은 100으로 설정하고 학습 수행
lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric="auc", eval_set=[(X_tr, y_tr), (X_val, y_val)])

lgbm_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])
print(f'ROC-AUC : {lgbm_roc_score}')
```
```
ROC-AUC : 0.5
```
LightGBM의 경우 학습시간이 상대적으로 빠르기 때문에 위에 기술된 하이퍼 파라미터 외에 추가적으로 튜닝을 수행해보는 것도 좋을거 같다.

----
## 언더 샘플링과 오버 샘플링의 이해
레이블이 불균형한 분포를 가진 Data set를 학습 시킬 때 예측성능의 문제가 발생할 수 있다. 이상 레이블을 가지는 데이터 건수가 매우 적기 때문에 제대로 다양한 유형을 학습하지 못하는 반면 정상 레이블을 가지는 데이터 건수가 매우 많기 때문에 생기는 문제이다. 그렇기 때문에 적절한 학습 데이터를 확보하는 방안이 필요한데, 대표적인 방안으로는 언더 샘플링과 오버 샘플링이 있다.

### 언더 샘플링
- 많은 데이터 셋을 적은 데이터 셋 수준으로 감소시키는 방식
- 정상 레이블이 10,000건, 이상레이블이 100 건이라면 정상 레이블 데이터도 100건으로 줄여버린다
- 과도하게 정상 레이블로 학습/예측하는 부작용은 개선되었지만 과도한 데이터 감소로 오히려 정상 레이블의 제대로된 학습 수행이 어려울 수 있다.

### 오버 샘플링
- 예측 성능상 더 유리한 경우가 많아 주로 사용된다
- 적은 데이터 셋을 많은 데이터 셋 수준으로 증가하여 맞추는 방식
- 단순히 동일 데이터를 증식한다면 과적합 될 수 있기 때문에, 원본 데이터 피처값을 약간 변경하며 증식한다
- 대표적으로는 SMOTE(Synthetic Minority Over-sampling Technique) 방법이 있다
- SMOTE 는 적은 데이터 셋에 있는 개별 데이터들의 K최근접 이웃(KNN)을 찾아 데이터와 K개의 이웃들 차이를 일정 값으로 만들어 기존 데이터와 약간의 차이가 나는 새로운 데이터들을 생성하는 방식이다.

----

# 분류 실습 - 캐글 신용카드 사기 검출
```python
import pandas as pd
import numpy as np

# 읽어오기
card_df = pd.read_csv("./creditcard.csv/creditcard.csv")
card_df[:3]
```
![](https://velog.velcdn.com/images/cyhse7/post/8d3d2f9b-0a25-4e18-ad97-fab517b4b076/image.png)
```python
card_df.shape
```
```
(284807, 31)
```
### 데이터 셋 분리
```python
# 데이터 셋 분리
from sklearn.model_selection import train_test_split

X_features = card_df.iloc[:,:-1]
y_lables = card_df.iloc[:,-1]

X_train, X_test, y_train, y_test = train_test_split(X_features, y_lables, test_size=0.3, random_state=0, stratify=y_lables)

# 나눠진 데이터 셋트들의 비율을 서로 환산하여 분할 비율 확인
print('학습데이터 레이블 값 비율')
print(y_train.value_counts()/len(y_train))
print()
print('테스트 데이터 레이블 값 비율')
print(y_test.value_counts()/len(y_test))
```
```
학습데이터 레이블 값 비율
0    0.998275
1    0.001725
Name: Class, dtype: float64

테스트 데이터 레이블 값 비율
0    0.998268
1    0.001732
Name: Class, dtype: float64
```
학습 데이터와 테스트 데이터의 1값이 약 0.0017로 큰차이없이 분할된것을 확인해 볼 수 있다.

### +) train_test_split의 stratify
- default=None
- classification을 다룰 때 매우 중요한 옵션값이다. stratify 값을 target으로 지정해주면 각각의 class 비율(ratio)을 train / validation에 유지해 줌. (한 쪽에 쏠려서 분배되는 것을 방지하는 것이다) 만약 이 옵션을 지정해 주지 않고 classification 문제를 다룬다면, 성능의 차이가 많이 날 수도 있다 함.

### 로지스틱 회귀
먼저 로지스틱 회귀를 이용하여 사기 여부를 예측해보겠다. 성능 평가는 전에 정의했던 사용자 함수 `get_clf_eval()` 함수를 다시 사용
```python
# 모델 생성
from sklearn.linear_model import LogisticRegression
lr_clf = LogisticRegression(max_iter = 1000)

# 학습/예측
lr_clf.fit(X_train, y_train)
preds = lr_clf.predict(X_test)

# output이 두개가 나오는데 뒤( =1값 =positive값)만 취하겠다.
lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]

# 성능 평가 사용자 정의함수
from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred)
    precision = precision_score(y_test , pred)
    recall = recall_score(y_test , pred)
    f1 = f1_score(y_test,pred)
    # ROC-AUC 추가 
    roc_auc = roc_auc_score(y_test, pred_proba)
    print('오차 행렬')
    print(confusion, '\n')
    # ROC-AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\
    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))

# 평가
get_clf_eval(y_test, preds, lr_pred_proba)
```
```
오차 행렬
[[85281    14]
 [   57    91]] 

정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702
```

### LGBMClassifier
이번에는 LGBMClassifier를 이용하여 모델을 학습한 뒤 별도의 테스트 데이터셋에서 예측 평가를 수행해보자
```python
# 모델 생성, fit, predict, evaluate
from lightgbm import LGBMClassifier
lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)
lgbm_clf.fit(X_train, y_train)
preds = lgbm_clf.predict(X_test)
lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]

# 오차행렬, 정확도, 정밀도, 재현율, f1, auc
get_clf_eval(y_test, preds, lgbm_pred_proba)
```
```
오차 행렬
[[85290     5]
 [   36   112]] 

정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790
```
로지스틱 회기에 비해서는 LGBM의 성능이 전체적으로 더 좋게 측정되었다.

-----

## 추가적으로 데이터 정제 후 적용
이번에는 왜곡된 분포도를 가지는 데이터를 재가공한 뒤에 모델을 다시 테스트 해보자. 위에서 사용했던 로지스틱 회귀의 경우 선형 모델이고, 대부분의 선형모델은 중요 피처값이 정규 분포 형태를 유지하는 것을 선호한다.

### 표준 정규분포 형태로 변환
Amount 피처는 신용 카드 사용 금액으로 정상/사기 트랜잭션을 결정하는 매우 중요한 속성일 가능성이 높으니 분포도를 확인해보자
```python
card_df['Amount'].describe()
```
```
count    284807.000000
mean         88.349619
std         250.120109
min           0.000000
25%           5.600000
50%          22.000000
75%          77.165000
max       25691.160000
Name: Amount, dtype: float64
```
시각화로 알아보기
```python
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 4))
plt.xticks(range(0, 30000, 1000), rotation=60)
sns.histplot(card_df['Amount'], bins=100, kde=True)
plt.show()
```
![](https://velog.velcdn.com/images/cyhse7/post/04f6a695-02a8-4db0-8a97-01bd9be4e490/image.png)
카드 사용 금액이 1000불 이하인 데이터가 대부분인 것이 한눈에 확인된다. Amount를 표준 정규 분포 형태로 변한한 뒤에 로지스틱 회귀의 예측 성능을 측정해보자.
```python
# 표준화 하기
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
card_df['Amount'] = scaler.fit_transform(card_df['Amount'].values.reshape(-1, 1))

card_df['Amount']
```
```
0         0.244964
1        -0.342475
2         1.160686
3         0.140534
4        -0.073403
            ...   
284802   -0.350151
284803   -0.254117
284804   -0.081839
284805   -0.313249
284806    0.514355
Name: Amount, Length: 284807, dtype: float64
```
```python
# 표준화 결과 평균이 0-분산이 1에 가까운 정규 분포형태가 되었는지 확인
print(f"평균\n{card_df['Amount'].mean()}")
print(f"분산\n{card_df['Amount'].var()}")
```
```
평균
-1.5966860045099457e-17
분산
1.000003511161984
```

로지스틱회귀와 LightGBM으로 학습/예측 후 사용자 정의 함수로 평가를 진행해보자
```python
# 데이터 셋 분리
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_features, y_lables, test_size=0.3, random_state=0, stratify=y_lables)

# 로지스틱 회귀 예측
lr_clf = LogisticRegression(max_iter = 1000)
lr_clf.fit(X_train, y_train)
preds = lr_clf.predict(X_test)
lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]
# 평가
print('로지스틱 회귀 예측')
get_clf_eval(y_test, preds, lr_pred_proba)


# LightGBM 예측 성능
from lightgbm import LGBMClassifier
lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)
lgbm_clf.fit(X_train, y_train)
preds = lgbm_clf.predict(X_test)
lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]
# 평가
print('\nLightGBM 예측 성능')
get_clf_eval(y_test, preds, lgbm_pred_proba)
```
```
로지스틱 회귀 예측
오차 행렬
[[85281    14]
 [   57    91]] 

정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702

LightGBM 예측 성능
오차 행렬
[[85290     5]
 [   36   112]] 

정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790
```
변환 전 수치
```
로지스틱 회귀 예측
[정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702]
LightGBM 예측 성능
[정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790]
```
위와 같았음으로 정말 큰차이가 안보이는 것을 확인할 수 있다. ~~안보이는 정도가 아니라 값이 같다~~

## 로그 변환 후 적용
로그 변환은 데이터 분포도가 심하게 왜곡 되어있을 경우 적용하는 중요 기법 중 하나. 원래 값을 log값으로 변환해 작은 값으로 변환하기 때문에 데이터 분포도의 왜곡을 상당 수준 개선해 준다.
```python
card_df_log = pd.read_csv("./creditcard.csv/creditcard.csv")
card_df_log.drop(['Time'], axis=1, inplace=True)

# log 변환하기
# numpy 의 log1p()함수를 이용해 변환해보자
card_df_log['Amount'] = np.log1p(card_df_log['Amount'])

# 데이터 셋 분리
from sklearn.model_selection import train_test_split
X_features = card_df_log.iloc[:,:-1]
y_lables = card_df_log.iloc[:,-1]
X_train, X_test, y_train, y_test = train_test_split(X_features, y_lables, test_size=0.3, random_state=0, stratify=y_lables)

# 로지스틱 회귀 예측
lr_clf = LogisticRegression(max_iter = 1000)
lr_clf.fit(X_train, y_train)
preds = lr_clf.predict(X_test)
lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]
# 평가
print('로지스틱 회귀 예측')
get_clf_eval(y_test, preds, lr_pred_proba)


# LightGBM 예측 성능
from lightgbm import LGBMClassifier
lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)
lgbm_clf.fit(X_train, y_train)
preds = lgbm_clf.predict(X_test)
lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]
# 평가
print('\nLightGBM 예측 성능')
get_clf_eval(y_test, preds, lgbm_pred_proba)
```
```
로지스틱 회귀 예측
오차 행렬
[[85283    12]
 [   59    89]] 

정확도: 0.9992, 정밀도: 0.8812, 재현율: 0.6014,    F1: 0.7149, AUC:0.9727

LightGBM 예측 성능
오차 행렬
[[85290     5]
 [   36   112]] 

정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790
```
변환 전 수치
```
로지스틱 회귀 예측
[정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702]
LightGBM 예측 성능
[정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790]
```
로지스틱의 경우 정밀도와 AUC는 조금 향상되었으나 재현율은 저하된 모습.
LightGBM의 경우는 변환전과 후가 같은 결과를 보이고 있다.

## 이상치 제거 후 적용
이상치를 찾는 방법은 여러가지가 있지만 이중에서 IQR(Inter Quantile Range) 방식을 적용한다. 모든 피처들의 이상치를 검출하는 것은 시간이 많이 소모되며, 결정값과 상관성이 높지 않은 피처들의 경우는 이상치를 제거하더라고 크게 성능 향상에 기여하지 않기 때문에 결정값(즉 레이블)과 가장 상관성이 높은 피처들을 위추로 이상치를 검출하는 것이 좋다.
```python
card_df_iqr = pd.read_csv("./creditcard.csv/creditcard.csv")
card_df_iqr.drop(['Time'], axis=1, inplace=True)
card_df_iqr[:3]
```
DataFrame의 corr()을 이용해 각 피처별로 상관도를 구한 뒤 heatmap 시각화 해보자. 양이 상관도가 높을수록 파란색에 가까우며, 음의 상관관계가 높을 수록 붉은 색에 가깝다.
```python
corr_M = card_df_iqr.corr()
sns.heatmap(corr_M, cmap="RdBu")
plt.show()
```
![](https://velog.velcdn.com/images/cyhse7/post/790bf37f-112e-40d4-aeef-9cc59d5ac262/image.png)
히트맵을 보면 음의 상관관계가 가장 높은 것이 v14와 v17로 나왔고 이중 v14에 대해서만 이상치를 찾아 제거해보도록 하자.
```python
# class 가 1인 경우에만 진행할 것이기 때문에 솎아준다.
fraud = card_df_iqr[card_df_iqr['Class'] == 1]
fraud
```
![](https://velog.velcdn.com/images/cyhse7/post/184ae5cf-f354-4b2a-8122-4457bba1ed80/image.png)
IQR 구하기
```python
# 넘파이 함수를 이용해 1/4분위와 3/4분위를 구하고, 이에 기반하여 IQR을 계산한다.
Q_25 = np.percentile(fraud.V14, 25)
Q_75 = np.percentile(fraud.V14, 75)
IQR = Q_75 -Q_25
IQR
# 5.409902115485521

# 또 다르게 IQR 계산하기
Q_25 = fraud['V14'].quantile(.25)
Q_75 = fraud['V14'].quantile(.75)
IQR = Q_75 - Q_25
IQR
# 5.409902115485521

# 구해진 IQR에 1.5를 곱해 최대값과 최소값 지점 구하기
upper_out = Q_75 + 1.5 * IQR
under_out = Q_25 - 1.5 * IQR

# 이상치 데이터 검색 
cond1 = fraud['V14'] >= upper_out
cond2 = fraud['V14'] <= under_out
fraud.V14[cond1 | cond2]
```
```
8296   -19.214325
8615   -18.822087
9035   -18.493773
9252   -18.049998
Name: V14, dtype: float64
```
이상치의 데이터 인덱스 담아주기
```python
temp = fraud.V14[cond1 | cond2].index
temp
```
```
Int64Index([8296, 8615, 9035, 9252], dtype='int64')
```
```python
card_df_iqr.shape
```
```
(284807, 30)
```
```python
# card_df에서 이상치를 제거해주세요
card_df_iqr.drop(labels = temp, axis = 0, inplace=True)

card_df_iqr.shape
```
```
(284803, 30)
```
제거 전 'shape (284807, 30)'에서 이상치 4개 제거하니 'shape (284803, 30)' 로 잘 사라진 것을 확인할 수 있다.
```python
# 데이터 셋 분리
from sklearn.model_selection import train_test_split
X_features = card_df_iqr.iloc[:,:-1]
y_lables = card_df_iqr.iloc[:,-1]
X_train, X_test, y_train, y_test = train_test_split(X_features, y_lables, test_size=0.3, random_state=0, stratify=y_lables)

# 로지스틱 회귀 예측
lr_clf = LogisticRegression(max_iter = 1000)
lr_clf.fit(X_train, y_train)
preds = lr_clf.predict(X_test)
lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]
# 평가
print('로지스틱 회귀 예측')
get_clf_eval(y_test, preds, lr_pred_proba)


# LightGBM 예측 성능
from lightgbm import LGBMClassifier
lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)
lgbm_clf.fit(X_train, y_train)
preds = lgbm_clf.predict(X_test)
lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]
# 평가
print('\nLightGBM 예측 성능')
get_clf_eval(y_test, preds, lgbm_pred_proba)
```
```
로지스틱 회귀 예측
오차 행렬
[[85279    16]
 [   48    98]] 

정확도: 0.9993, 정밀도: 0.8596, 재현율: 0.6712,    F1: 0.7538, AUC:0.9739

LightGBM 예측 성능
오차 행렬
[[85291     4]
 [   25   121]] 

정확도: 0.9997, 정밀도: 0.9680, 재현율: 0.8288,    F1: 0.8930, AUC:0.9791
```
변환 전 수치와 비교하여
```
로지스틱 회귀 예측
[정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702]
LightGBM 예측 성능
[정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790]
```
로지스틱의 경우 정확도와 재현율, f1, auc 가 향상 되었으나 정밀도는 조금 떨어진 모습
LightGBM의 경우 5가지 모두 전반적으로 향상된 모습을 확인 가능

## log와 이상치 제거를 함께 한다면?
```python
# card_df_iqr 데이터에 log 적용
card_df_iqr['Amount'] = np.log1p(card_df_iqr['Amount'])

# 데이터 셋 분리
from sklearn.model_selection import train_test_split
X_features = card_df_iqr.iloc[:,:-1]
y_lables = card_df_iqr.iloc[:,-1]
X_train, X_test, y_train, y_test = train_test_split(X_features, y_lables, test_size=0.3, random_state=0, stratify=y_lables)

# 로지스틱 회귀 예측
lr_clf = LogisticRegression(max_iter = 1000)
lr_clf.fit(X_train, y_train)
preds = lr_clf.predict(X_test)
lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]
# 평가
print('로지스틱 회귀 예측')
get_clf_eval(y_test, preds, lr_pred_proba)


# LightGBM 예측 성능
from lightgbm import LGBMClassifier
lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)
lgbm_clf.fit(X_train, y_train)
preds = lgbm_clf.predict(X_test)
lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]
# 평가
print('\nLightGBM 예측 성능')
get_clf_eval(y_test, preds, lgbm_pred_proba)
```
```
로지스틱 회귀 예측
오차 행렬
[[85281    14]
 [   48    98]] 

정확도: 0.9993, 정밀도: 0.8750, 재현율: 0.6712,    F1: 0.7597, AUC:0.9743

LightGBM 예측 성능
오차 행렬
[[85291     4]
 [   25   121]] 

정확도: 0.9997, 정밀도: 0.9680, 재현율: 0.8288,    F1: 0.8930, AUC:0.9791
```
이상치 제거만 했을 때는 아래와 같았다.
```
로지스틱 회귀 예측
[정확도: 0.9993, 정밀도: 0.8596, 재현율: 0.6712,    F1: 0.7538, AUC:0.9739]

LightGBM 예측 성능
[정확도: 0.9997, 정밀도: 0.9680, 재현율: 0.8288,    F1: 0.8930, AUC:0.9791]
```
함께 했을 때.. 로지스틱의 경우 정밀도와 f1, auc가 향상되었다.
LightGBM의 경우변화가 없는 모습.
성능이 떨어지지는 않았으니 같이 하는 것이 나쁘지는 않은 선택같이 보이는 결과를 주었다.

## SMOTE 오버 샘플링 적용
SMOTE를 적용할 때에는 반드시 학습 데이터 셋만 오버 샘플링을 해야한다. 검증 데이터 셋이나 테스트 데이터 셋을 오버 샘플링할 경우 결국은 원본 데이터 세트가 아닌 데이터 세트에서 검증 또는 테스트를 수행하기 때문에 올바른 검증/테스트가 될수 없기 때문이다.

패키지 설치
```python
# SMOTE를 구현한 대표적인 파이썬 패키지 설치
!pip install imbalanced-learn
```
데이터 증식
```
from imblearn.over_sampling import SMOTE

# test는 건드리면 안된다. 따라서 train만 건드리기
smote = SMOTE(random_state=0)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
print(f'SMOTE 적용전 학습용 피처/레이블 데이터 셋 : {X_train.shape}, {y_train.shape}')
print(f'SMOTE 적용후 학습용 피처/레이블 데이터 셋 : {X_train_smote.shape}, {y_train_smote.shape}')
print(f'SMOTE 적용후 레이블 값 분포 : \n{pd.Series(y_train_smote).value_counts()}')
```
```
SMOTE 적용전 학습용 피처/레이블 데이터 셋 : (199362, 29), (199362,)
SMOTE 적용후 학습용 피처/레이블 데이터 셋 : (398040, 29), (398040,)
SMOTE 적용후 레이블 값 분포 : 
0    199020
1    199020
Name: Class, dtype: int64
```
SMOTE 오버 샘플링 이후 데이터가 대략 2배 정도 증가한 모습이며, 레이블 값의 0과 1의 분포가 동일하게 생성된 모습을 확인할 수 있다.
```python
# 로지스틱 회귀 예측
lr_clf = LogisticRegression(max_iter = 1000)
lr_clf.fit(X_train, y_train)
preds = lr_clf.predict(X_test)
lr_pred_proba = lr_clf.predict_proba(X_test)[:,1]
# 평가
print('로지스틱 회귀 예측')
get_clf_eval(y_test, preds, lr_pred_proba)


# LightGBM 예측 성능
from lightgbm import LGBMClassifier
lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)
lgbm_clf.fit(X_train, y_train)
preds = lgbm_clf.predict(X_test)
lgbm_pred_proba = lgbm_clf.predict_proba(X_test)[:,1]
# 평가
print('\nLightGBM 예측 성능')
get_clf_eval(y_test, preds, lgbm_pred_proba)
```
```
로지스틱 회귀 예측
오차 행렬
[[85281    14]
 [   48    98]] 

정확도: 0.9993, 정밀도: 0.8750, 재현율: 0.6712,    F1: 0.7597, AUC:0.9743

LightGBM 예측 성능
오차 행렬
[[85291     4]
 [   25   121]] 

정확도: 0.9997, 정밀도: 0.9680, 재현율: 0.8288,    F1: 0.8930, AUC:0.9791
```
SMOTE 이전 수치는 아래와 같았는데
```
로지스틱 회귀 예측
[정확도: 0.9992, 정밀도: 0.8667, 재현율: 0.6149,    F1: 0.7194, AUC:0.9702]
LightGBM 예측 성능
[정확도: 0.9995, 정밀도: 0.9573, 재현율: 0.7568,    F1: 0.8453, AUC:0.9790]
```
로지스틱의 경우 전체적으로 조금씩 향상되었고, LightGBM의 경우에도 전체적으로 조금씩 향상된 모습을 보였다.

### boost_from_average=Ture

레이블값이 극도로 불균형한 경우 `boost_from_average=Ture`로 설정할 경우 성능이 저하된다고 하여 테스트 해봤다.
```python
# 반복적으로 쓰이고 있으니 사용자 함수로 정의
def get_model_train_eval(model, train_x=None, test_x=None, train_y=None, test_y=None):
    model.fit(train_x, train_y)
    pred = model.predict(test_x)
    pred_proba = model.predict_proba(test_x)[:,1]
    get_clf_eval(test_y, pred, pred_proba)


print('LightGBM : boost_from_average=True 예측 성능')
lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=True)
get_model_train_eval(lgbm_clf, train_x=X_train, test_x=X_test, train_y=y_train, test_y=y_test)

print('\nLightGBM 예측 성능')
lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)
get_model_train_eval(lgbm_clf, train_x=X_train, test_x=X_test, train_y=y_train, test_y=y_test)
```
```
LightGBM : boost_from_average=True 예측 성능
오차 행렬
[[85268    27]
 [   36   110]] 

정확도: 0.9993, 정밀도: 0.8029, 재현율: 0.7534,    F1: 0.7774, AUC:0.9219

LightGBM 예측 성능
오차 행렬
[[85291     4]
 [   25   121]] 

정확도: 0.9997, 정밀도: 0.9680, 재현율: 0.8288,    F1: 0.8930, AUC:0.9791
```
정말 옵션값만 True / False로 설정해줬을 뿐인데 모든 값에서 값이 떨어진 것을 확인할 수 있었다. 가중치 업데이트 시 평균값에서 시작하게 하는 옵션이라는데 데이터가 불균형하기 때문에 평균값도 올바르지 않아서(? 그런것일까...

LightGBM 2.1.0 이상 버전에서 `boost_from_average` 파라미터 디폴트 값은 True이기 때문에 데이터 값이 불균형하면 False 로 꺼주는 것을 잊지 말자.

boost_from_average 파라미터 정보 참고 : [lightGBM/XGBoost 파라미터 설명](http://machinelearningkorea.com/2019/09/29/lightgbm-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0/)


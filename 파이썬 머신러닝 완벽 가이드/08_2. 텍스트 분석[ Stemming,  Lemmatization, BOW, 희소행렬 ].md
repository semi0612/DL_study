
## Stemming과 Lemmatization
Steam : 어간
Stemming
- 어간추출
- 단어의 원형을 찾는데, 원형 단어로 변환 시 일반적인 방법을 적용하거나 더 단순화된 방법을 적용해 원래 단어에서 일부 철자가 훼손된 어근단어를 추출하는 경향이 있다.
- plays -> play

Lemmatization
- 표제어 추출
- 품사와 같은 문법적인 요소와 더 의미적인 부분을 감안해 정확한 철자로 된 어근 단어를 찾아준다.
- is, was -> be

Lemmatizaiton이 Stemming보다 의미론적인 기반에서 원형을 찾기 때문에 더 정교하다고 볼 수 있다.

### Stemming
```python
# Stemming
from nltk.stem import LancasterStemmer
stemmer = LancasterStemmer()

print(stemmer.stem('plays'), stemmer.stem('playing'), stemmer.stem('played'))
print(stemmer.stem('working'), stemmer.stem('works'), stemmer.stem('worked'))
print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))
print(stemmer.stem('happier'),stemmer.stem('happiest'))
print(stemmer.stem('fancier'),stemmer.stem('fanciest'))
```
```
play play play
work work work
amus amus amus
happy happiest
fant fanciest
```
play나 work의 경우 기본단어로 잘 되돌아왔으나, amuse의 경우 기본단어에 ing, s, ed가 붙었다는 이유로 정확한 단어가 아닌 amus로 되돌린 모습을 확인할 수 있었다. 형용사인 happy와 fancy이 경우도 비교형, 최상급형으로 변형된 단어의 정확한 원형을 찾지 못하고 원형 단어에서 철자가 다른 어근 단어로 인식하는 경우가 발생했다.

### Lemmatization
```python
# Lemmatization
from nltk.stem import WordNetLemmatizer
lemma = WordNetLemmatizer()

# 책에서는 'wordnet'이였지만 바뀐듯 하다
nltk.download('omw-1.4')

# 동사: v, 형용사: a
print(lemma.lemmatize('plays', 'v'))
print(lemma.lemmatize('is', 'v'), lemma.lemmatize('was', 'v'), lemma.lemmatize('being', 'v'))
print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),lemma.lemmatize('amused','v'))
print(lemma.lemmatize('happier','a'),lemma.lemmatize('happiest','a'))
print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))
```
```
play
be be be
amuse amuse amuse
happy happy
fancy fancy
```
Lemmatization에선 정확한 원형 단어 추출을 위해 품사를 기입하여야 하는 귀찮음이 있지만, Stemming보다는 정확하게 원형 단어를 추출해내는 걸 볼 수 있었다. 사전을 기반으로 단어를 처리하기 때문에 오류는 적은 편이나 새로운 단어는 처리 할 수 없다는 단점이 있다.

----

## 피처 벡터화 (Bag of Words - BOW)
문서가 가지는 모든 단어(words)를 문맥이나 순서를 무시하고 일괄적으로 단어에 대해 빈도 값을 부여 한 뒤 피처 값을 추출하는 모델이다. 쉽고 빠른 구축이 가능하지만 단어의 순서를 고려하지 않으므로 문맥적인 의미 반영이 부족하고 희소 행렬(대부분의 값이 0)의 문제가 있다.

### Count 벡터화
- 단어 피처에 값을 부여할 때 각 문서에서 해당 단어가 나타나는 횟수
- 단순하게 모든 단어의 빈도로 피처 벡터화를 진행한다.
- 카운트 벡터화에서는 카운트 값이 높을 수록 중요한 단어로 인식하는 문제
- CountVectorizer()는 다음과 같이 작업을 수행한다.
→ 소문자 일괄 변환, 각 단어를 토큰화, 텍스트 전처리(스톱 워드 제거), 피처 벡터화

### TF-IDF 벡터화
- Term Frequency Inverse Document Frequency
- 개별 문서에서 자주 나타내는 단어에 높은 가중치를 주되, 모든 문서에서 전반적으로 자주 나타나는 단어에 대해서는 페널티를 주는 방식으로 값을 부여한다.

----

## 희소 행렬
모든 문서의 단어를 피처로 벡터화 하면 컬럼이 많아질 수 밖에 없다. 하지만 행렬은 대규모로 생성되어도 단어의 종류에 비해 각 문서가 가지는 단어의 수는 제한적이기 때문에 이 행렬의 값은 대부분 0이 차지할 수 밖에 없다. 이처럼 대규모 행렬의 대부분 값을 0이 차지하는 행렬을 가리켜 희소행렬이라 한다.

BOW 형태를 가진 언어 모델의 피처 벡터화는 대부분 희소행렬이다. 희소 행렬은 불필요한 0값이 너무 많아 메모리 공간이 많이 필요하며 연산 시간도 오래 걸리게 되는 단점이 있는데, 이러한 희소행렬이 적은 메모리 공간을 차지하게 변환하는 2가지 방법이 있다.

### COO 형식
COO(Coordinate: 좌표) 형식은 0이 아닌 데이터만 별도의 배열에 저장하고, 그 데이터가 가리키는 행과 열의 위치를 별도의 배열로 저장하는 방식이다.

sparse 패키지의 coo_matrix를 이용해 COO형식으로 희소 행렬 생성할수 있다.
```python
from scipy import sparse

# 희소행렬 만들기
data = np.array([3, 1, 2])
row = np.array([0, 0, 1])
col = np.array([0, 2, 1])

# sparse 패키지의 coo_matrix를 이용해 COO형식으로 희소 행렬 생성
# coo_matrix((M, N), [dtype])
sparse_coo = sparse.coo_matrix((data, (row, col)))

sparse_coo.toarray()
```
```
array([[3, 0, 1],
       [0, 2, 0]])
```
위와같이 넣으려면 (())의 형태로 넣어야 하는 점을 명시하자. sparse_coo로 담아준 것의 COO형식의 희소 행렬 객체이고, toarray()를 이용해주면 다시 밀집 형태의 행렬로 출력 가능하다.

----

### CSR 형식
COO 형식은 행과 열의 위치를 나타내기 위해 반복적으로 위치 데이터를 사용하는데 이를 해결한 방식이 CSR(Compressed Sparse Row) 형식이다. 간단하게 말하자면 COO에서 행 위치 배열을 다시 위치 시작 배열로 생성하는 것이다.

```python
# dense2를 위처럼 생성하세요
# dense2 = np.array([[0,0,1,0,0,5],
#                   [1,4,0,3,2,5],
#                   [0,6,0,3,0,0],
#                   [2,0,0,0,0,0],
#                   [0,0,0,7,0,8],
#                   [1,0,0,0,0,0]])

# 0이 아닌 데이터
data = np.array([1, 5, 1, 4, 3, 2, 5, 6, 3, 2, 7, 8, 1])

# 행과 열 위치를 각각 배열로 생성
row = np.array([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 5])
col = np.array([2, 5, 0, 1, 3, 4, 5, 1, 3, 0, 3, 5, 0])

# 
sparse.coo_matrix((data, (row, col))).toarray()
```
```
array([[0, 0, 1, 0, 0, 5],
       [1, 4, 0, 3, 2, 5],
       [0, 6, 0, 3, 0, 0],
       [2, 0, 0, 0, 0, 0],
       [0, 0, 0, 7, 0, 8],
       [1, 0, 0, 0, 0, 0]])
```
위가 COO형식의 변환이라면
```python
# 행 위치 배열의 고유한 값에 시작 위치 인덱스를 배열로 생성
row_index = np.array([0, 2, 7, 9, 10, 12, 13])
sparse_csr = sparse.csr_matrix((data, col, row_index))
sparse_csr.toarray()
```
```
array([[0, 0, 1, 0, 0, 5],
       [1, 4, 0, 3, 2, 5],
       [0, 6, 0, 3, 0, 0],
       [2, 0, 0, 0, 0, 0],
       [0, 0, 0, 7, 0, 8],
       [1, 0, 0, 0, 0, 0]])
```
이것이 CSR형식의 변환이다. 방법이 조금 헷갈렸는데 교재의 아래 사진을 보면 이해가 쉽다.
![](https://velog.velcdn.com/images/cyhse7/post/3ebebda4-5df0-42e9-903d-10f90aa4244e/image.jpg)
이렇게 고유값의 시작위치만 알고 있으면 얼마든지 행 위치 배열을 다시 만들수 있기에 COO방식보다 메모리가 적게 들고 빠른 연산이 가능하다.

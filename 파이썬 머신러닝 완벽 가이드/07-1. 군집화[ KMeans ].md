위키북스의 '파이썬 머신러닝 완벅 가이드' 개정 2판으로 공부하고 있습니다. 실습 과정과 이해에 따라 내용의 누락 및 코드의 변형이 있을 수 있습니다.

-----


# 군집화
### 분류 vs 군집화
`분류(Classification)`
- 범주의 수 및 각 개체의 범주 정보를 '사전에 알 수 있으며', 입력 변수 값으로부터 범주 정보를 유추하여 새로운 개체에 대해 가장 적합한 범주로 할당하는 문제
- 지도학습

`군집화(Clustering)`
- 군집의 수, 속성등이 '사전에 알려져있지 않으며' 최적의 구분을 찾아가는 문제
- 비지도 학습

### 군집분석(Clustering) 이란?
각 개체의 동질성을 측정하여 동질성이 높은 '대상 군집'을 탐색하고, 군집에 속한 개체들의 동질성과 서로 다른 군집에 속한 개체간의 이질성을 규명하는 통계 분석 방법

## K-평균 알고리즘 이해
K-평균은 군집화에서 가장 일반적으로 사용되는 알고리즘이다. 특정한 임의의 지점을 선택해 해당 중심에 가장 가까운 포인트들을 선택하는 군집화 기법이다.

### 수행과정
1. K 값을 초기값으로 먼저 받고, K개의 초기 군집의 임의 중심점을 설정한다
2. 각 개체와 군집 중심점 사이의 거리를 계산한다.
3. 가장 가까운 중심점 군집으로 재할당한다
4. 변경된 군집을 기준으로 개체와 군집 중심점 사이의 거리를 다시 계산
5. 3~4 단계를 군집의 변동이 없을 때까지 반복한다.

	↓
1. 군집 중심점(centroid)라는 특정한 임의의 지점을 선택해 해당 중심에 가장 가까운 포인트들을 선택
2. 군집 중심점은 선택된 포인트의 평균 지점으로 이동하고 이동된 중심점에서 다시 가까운 포인트를 선택한다
3. 이 과정을 반복하다가 더이상 중심점의 이동이 없으면 반복을 멈추고 해당 중심점에 속하는 포인트들을 군집화 한다.

### 장점
- 알고리즘이 쉽고 간결하다(계산 시간 짧음)
- 비지도학습이기 때문에 사전 라벨 데이터가 필요없다
- 데이터 변환 없이 그 자체로 이용할 수 있어 데이터 구조가 간단하다

### 단점
- 거리 기반의 알고리즘이므로 속성(피처)의 개수가 많으면 군집화 정확도가 떨어진다
- 반복 횟수가 많아지면 수행 시간이 매우 느려진다.
- 초기 군집 수(K)에 따라 결과가 달라지는데, 몇 개의 군집을 선택해야 할지 가이드 하기가 어렵다. (K 설정에 대한 가이드가 어렵다)
- 범주형 변수 사용이 불가하다

### KMeans 클래스(사이킷 런)
KMeans 클래스는 아래와 같은 초기화 파라미터를 가지고 있다.
```
KMean(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001,
	precompute_distances='auto', verbose=0, random_state=None,
    copy_x=True, n_jobs=1, algorithm='auto')
```
`n_clusters` : 초기 파라미터 중 가장 중요한 파라미터. 군집화할 개수 = 군집 중심점의 개수를 의미한다
`init` : 초기에 군집 중심점의 좌표를 설정할 방식을 말한다. 보통은 임의로 중심을 설정하지 않고 'k-means++' 방식으로 최초 설정한다
`max_iter` : 최대 반복 횟수. 이 횟수 이전에도 모든 데이터의 중심점 이동이 없으면 종료한다.

군집화와 관련된 주요 속성은 아래와 같다.
`labels_` : 각 데이터 포인트가 속한 군집 중심점 레이블
`cluster_centers_` : 각 군집 중심점 좌표(Shape는 [군집 개수, 피처 개수]). 이를 이용하면 군집 중심점 좌표가 어디인지 시각화할 수 있다.



### 붓꽃 데이터로 K-평균 세트 군집화
`sklearn.cluster`의 KMeans()로 K-Means를 수행할 수 있다.
```python
from sklearn.preprocessing import scale
from sklearn.datasets import load_iris
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# 데이터 불러오기 및 DataFrame으로 변환(+컬럼명 변환
iris = load_iris()
X_feature = iris.data
y_label = iris.target

# target 변수를 제외하고 데이터 프레임으로 생성
iris_df = pd.DataFrame(data=X_feature, columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])
iris_df[:3]
```
![](https://velog.velcdn.com/images/cyhse7/post/c704b172-9ed4-4259-915f-11fee667acb0/image.png)
붓꽃 데이터 세트를 3개의 그룹으로 군집화해보자. k-means는 데이터를 나누는(train_test_split) 과정이 필요하지 않다. 바로 KMeans 사용해보자
```python
kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, random_state=0)
# 책에서는 kmeans.fit(iris_df)
kmeans.fit(X_feature)
```
![](https://velog.velcdn.com/images/cyhse7/post/c9f27397-e6a8-4dae-9685-ec1d87c92e1e/image.png)
fit() 수행시 iris_df 데이터에 대한 군집화 수행 결과가 kmeans 객체 변수로 반환되었을 것이다. 속성값을 출력해보면 데이터가 어떤 중심에 속해있는지 알 수 있다고 함
```python
print(pd.Series(kmeans.labels_).value_counts())
```
```
2    61
0    50
1    39
dtype: int64
```
n_clusters 값을 3으로 주었으니, 값이 0, 1, 2,로 분류된 모습을 확인할 수 있었다.
```python
kmeans.labels_
```
```
array([1, 0, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 2, 2, 0, 1, 1, 2,
       0, 0, 1, 0, 2, 1, 1, 1, 0, 0, 1, 0, 2, 2, 0, 2, 2, 1, 2, 1, 1, 1,
       0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 1, 1, 2, 2, 0, 0, 1, 1, 0, 2, 2, 1,
       2, 2, 1, 2, 2, 0, 0, 1, 0, 1, 2, 2, 2, 1, 1, 0, 0, 2, 2, 0, 0, 1,
       0, 2, 1, 1, 2, 0, 2, 0, 0, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 0, 1, 2,
       0, 1, 2, 1, 0, 0, 0, 2, 1, 1, 2, 2, 1, 0, 2, 0, 1, 2, 1, 0, 1, 2,
       2, 2, 0, 2, 2, 0, 2, 1, 1, 1, 0, 2, 2, 0, 1, 1, 2, 0, 2, 1, 1, 1,
       0, 2, 2, 2, 0, 0, 2, 1, 1, 1, 0, 0, 2, 1, 2, 2, 0, 2, 0, 2, 1, 1,
       0, 1, 0, 2, 0, 1, 2, 2, 2, 0, 1, 2, 0, 0, 1, 1, 2, 2, 2, 2, 1, 2,
       0, 2])
```
`labels_` 속성은 각 데이터 포인트가 속한 군집 중심점 레이블이다.
```python
iris_df['target'] = iris.target
iris_df['cluster'] = kmeans.labels_

iris_result = iris_df.groupby(['target','cluster']).size()
iris_result
```
```
target  cluster
0       1          50
1       0          48
        2           2
2       0          14
        2          36
dtype: int64
```
- target이 0인 데이터는 모두 1번 군집으로 잘 분류
- target이 1인 데이터는 2개만 0번 군집으로, 나머지는 2번 군집으로 분류
- target이 2인 데이터는 36개가 0번 군집으로, 14개가 2번 군집으로 분류

----

### 군집화 알고리즘 테스트를 위한 데이터 생성
사이킷런 패키지에는 다양한 유형의 군집화 알고리즘을 테스트해보기 위한 간단한 데이터 생성기를 제공한다. 대표적인 군집화용 데이터 생성기로는 `make_blobs()`와 `make_classification()` API가 있다. 

- `make_blobs()` : 대표적인 군집화 데이터 생성기로 개별 군집의 중심점과 표준 편차 제어 기능이 있다.
- `make_classfication()` : 역시 대표적인 군집화 데이터 생성기로 노이즈를 추가할 수 있다.

<br>

make_blobs()를 이용해 가상데이터를 생성한다.
```python
from sklearn.datasets import make_blobs

# make_blobs 로 데이터 생성
X, y = make_blobs(n_samples=200, n_features=2, centers=3, cluster_std=0.8, random_state=0)
print(X.shape, y.shape)

# target 값 분포
unique, counts = np.unique(y, return_counts=True)
print(unique, counts)
```
```
(200, 2) (200,)
[0 1 2] [67 67 66]
```
`centers`는 군집의 개수인데, 만약 ndarray 형태로 입력하면 개별 군집 중심점의 좌표로 인식하게 된다. `cluster_std`는 생성될 군집 데이터의 표준편차를 의미하며 각 군집별로 설정이 가능.

좀 더 데이터 가공을 편리하게 하기 위해서 위 데이터 세트를 DataFrame화 후 시각화 해보자
```python
# 데이터 프레임 생성
cluster_df = pd.DataFrame(X, columns=["ftr1","ftr2"])
cluster_df["target"] = y

# target 값 종류
target_list = np.unique(y)

# 가상 데이터 시각화
markers=['o', 's', '^']

for target in target_list:
    target_cluster = cluster_df[cluster_df['target'] == target]
    plt.scatter(x=target_cluster['ftr1'], y=target_cluster['ftr2'], 
                edgecolor='k', marker=markers[target] )
    
plt.show()
```
![](https://velog.velcdn.com/images/cyhse7/post/ab0f15b8-1f44-42f3-8db0-271f77bf4281/image.png)

이렇게 만들어진 데이터 세트에 KMeans 군집화를 수행한 뒤에 군집별로 시각화해 보자.
```python
# K-Means 객체 생성
kmeans = KMeans(n_clusters=3, init="k-means++", max_iter=200, random_state=0)

# cluster label (fit 후 labels_, fit_predict의 결과가 같았다.)
cluster_labels = kmeans.fit_predict(cluster_df.iloc[:,:-1])
cluster_df["kmeans_label"] = cluster_labels

# 개별 클러스터의 중심 위치 좌표
centers = kmeans.cluster_centers_
```
K-Means를 수행하고 데이터 프레임에 cluster label을 추가, 이후 cluster_centers_ 속성의 각 군집 중심점 좌표를 시각화를 위해 추출하였다.

![](https://velog.velcdn.com/images/cyhse7/post/f91b89a4-9795-44d0-9b4e-b2f75cf82d35/image.png)
각 군집과 군집별 중심위치를 시각화하였다. 음 제법 잘 매핑 된것으로 보인다...
```python
cluster_df.groupby(['target','kmeans_label']).size()
```
```
target  kmeans_label
0       0               66
        1                1
1       2               67
2       1               65
        2                1
dtype: int64
```
실제로 target 0,2에서 각각 1건씩만 다르게 분류되고 나머지는 잘 매핑된 모습!
